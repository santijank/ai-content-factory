# AI Content Factory - Production Docker Compose
# ðŸš€ Production-ready configuration with high availability and security
# âš ï¸  Do not use for development - use docker-compose.yml instead

version: '3.8'

# ========================
# Networks
# ========================
networks:
  ai-content-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16
  monitoring:
    driver: bridge
  db-network:
    driver: bridge
    internal: true  # Database network is internal only

# ========================
# Volumes
# ========================
volumes:
  postgres_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /opt/ai-content-factory/data/postgres
  redis_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /opt/ai-content-factory/data/redis
  n8n_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /opt/ai-content-factory/data/n8n
  uploads:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /opt/ai-content-factory/uploads
  logs:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /var/log/ai-content-factory
  ssl-certs:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /opt/ai-content-factory/ssl
  prometheus_data:
    driver: local
  grafana_data:
    driver: local

# ========================
# Services
# ========================
services:
  # ========================
  # SSL Certificate Management
  # ========================
  certbot:
    image: certbot/certbot:latest
    container_name: ai-content-certbot
    restart: "no"  # Run on-demand or via cron
    volumes:
      - ssl-certs:/etc/letsencrypt
      - ./certbot/www:/var/www/certbot
    command: >
      sh -c "while :; do
        certbot renew --webroot --webroot-path=/var/www/certbot --quiet &&
        nginx -s reload;
        sleep 12h;
      done"
    depends_on:
      - nginx
    deploy:
      resources:
        limits:
          cpus: '0.1'
          memory: 128M

  # ========================
  # Health Check Service
  # ========================
  healthcheck:
    image: ai-content-factory/healthcheck:${DOCKER_IMAGE_TAG:-latest}
    container_name: ai-content-healthcheck
    restart: always
    environment:
      - CHECK_INTERVAL=30
      - NOTIFICATION_WEBHOOK=${SLACK_WEBHOOK_URL}
      - SERVICES=postgres,redis,content-engine,platform-manager,trend-monitor,web-dashboard,n8n
    networks:
      - ai-content-network
      - db-network
      - monitoring
    volumes:
      - logs:/var/log/healthcheck
    depends_on:
      - postgres
      - redis
      - content-engine
      - platform-manager
      - trend-monitor
      - web-dashboard
      - n8n
    deploy:
      resources:
        limits:
          cpus: '0.1'
          memory: 128M

  # ========================
  # Queue Worker (for background jobs)
  # ========================
  queue-worker:
    image: ai-content-factory/content-engine:${DOCKER_IMAGE_TAG:-latest}
    container_name: ai-content-queue-worker
    restart: always
    command: ["node", "workers/queue-worker.js"]
    env_file:
      - ./config/environment/production.env
    environment:
      - NODE_ENV=production
      - WORKER_TYPE=queue
      - DATABASE_URL=postgresql://${DB_USER}:${DB_PASSWORD}@postgres:5432/${DB_NAME}
      - REDIS_URL=redis://:${REDIS_PASSWORD}@redis:6379/0
      - QUEUE_CONCURRENCY=10
    volumes:
      - uploads:/app/uploads
      - logs:/var/log/app
    networks:
      - ai-content-network
      - db-network
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    deploy:
      replicas: 3
      resources:
        limits:
          cpus: '1'
          memory: 1G
        reservations:
          memory: 512M
      restart_policy:
        condition: any
        delay: 10s
        max_attempts: 3
        window: 120s

  # ========================
  # Scheduler (for cron jobs)
  # ========================
  scheduler:
    image: ai-content-factory/scheduler:${DOCKER_IMAGE_TAG:-latest}
    container_name: ai-content-scheduler
    restart: always
    env_file:
      - ./config/environment/production.env
    environment:
      - NODE_ENV=production
      - DATABASE_URL=postgresql://${DB_USER}:${DB_PASSWORD}@postgres:5432/${DB_NAME}
      - REDIS_URL=redis://:${REDIS_PASSWORD}@redis:6379/0
    volumes:
      - logs:/var/log/scheduler
    networks:
      - ai-content-network
      - db-network
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/health"]
      interval: 60s
      timeout: 10s
      retries: 3
      start_period: 30s
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          memory: 256M

# ========================
# Production Deployment Configuration
# ========================

# Environment-specific settings
x-production-defaults: &production-defaults
  restart: always
  logging:
    driver: "json-file"
    options:
      max-size: "10m"
      max-file: "3"
  deploy:
    restart_policy:
      condition: on-failure
      delay: 5s
      max_attempts: 3
      window: 120s

# Resource limits template
x-resource-limits: &resource-limits
  deploy:
    resources:
      limits:
        cpus: '1'
        memory: 1G
      reservations:
        memory: 512M

# Health check template
x-health-check: &health-check
  healthcheck:
    interval: 30s
    timeout: 10s
    retries: 3
    start_period: 30s

# Security template
x-security: &security
  security_opt:
    - no-new-privileges:true
  cap_drop:
    - ALL
  cap_add:
    - NET_BIND_SERVICE
  read_only: true
  tmpfs:
    - /tmp
    - /var/run

# ========================
# Production Override Examples
# ========================

# To run specific services only:
# docker-compose -f docker-compose.prod.yml up postgres redis content-engine

# To scale services:
# docker-compose -f docker-compose.prod.yml up --scale content-engine=5 --scale queue-worker=10

# To run with specific profile:
# docker-compose -f docker-compose.prod.yml --profile monitoring up

# ========================
# Production Profiles
# ========================
# Use profiles to control which services run in different scenarios

# Monitoring profile
services:
  prometheus:
    profiles: ["monitoring"]
  grafana:
    profiles: ["monitoring"]
  node-exporter:
    profiles: ["monitoring"]
  cadvisor:
    profiles: ["monitoring"]

# Backup profile
  backup:
    profiles: ["backup"]
  
# Maintenance profile
  certbot:
    profiles: ["maintenance"]

# ========================
# Production Commands
# ========================

# Start all core services:
# docker-compose -f docker-compose.prod.yml up -d

# Start with monitoring:
# docker-compose -f docker-compose.prod.yml --profile monitoring up -d

# Run backup:
# docker-compose -f docker-compose.prod.yml run --rm backup

# Update SSL certificates:
# docker-compose -f docker-compose.prod.yml run --rm certbot

# View logs:
# docker-compose -f docker-compose.prod.yml logs -f [service-name]

# Scale services:
# docker-compose -f docker-compose.prod.yml up -d --scale content-engine=5

# Rolling update:
# docker-compose -f docker-compose.prod.yml pull
# docker-compose -f docker-compose.prod.yml up -d --no-deps content-engine

# Health check all services:
# docker-compose -f docker-compose.prod.yml ps

# Stop gracefully:
# docker-compose -f docker-compose.prod.yml down --timeout 30

# Emergency stop:
# docker-compose -f docker-compose.prod.yml kill

# ========================
# Production Security Notes
# ========================

# 1. Network Security:
#    - All databases are on internal networks only
#    - Services exposed through reverse proxy only
#    - No direct external access to internal services

# 2. Container Security:
#    - All containers run with minimal privileges
#    - Read-only root filesystems where possible
#    - No new privileges allowed
#    - Specific capability drops and adds

# 3. Data Security:
#    - All sensitive data in named volumes
#    - SSL/TLS encryption for all external communications
#    - Database connections encrypted
#    - Secrets injected via environment variables

# 4. Monitoring Security:
#    - All monitoring tools on separate network
#    - Access restricted to localhost only
#    - Authentication required for all monitoring interfaces

# ========================
# Production Maintenance
# ========================

# Regular tasks that should be automated:

# 1. Daily:
#    - Database backups
#    - Log rotation
#    - Health checks
#    - Security scans

# 2. Weekly:
#    - SSL certificate renewal check
#    - Performance metrics review
#    - Dependency updates check
#    - Resource utilization review

# 3. Monthly:
#    - Security patches
#    - Backup restoration tests
#    - Disaster recovery tests
#    - Performance optimization

# ========================
# Production Monitoring
# ========================

# Key metrics to monitor:
# - CPU and memory usage per service
# - Database connection pool status
# - Redis memory usage and hit rates
# - API response times and error rates
# - Queue length and processing times
# - SSL certificate expiration dates
# - Disk space usage
# - Network traffic patterns

# Alerting thresholds:
# - CPU usage > 80% for 5 minutes
# - Memory usage > 90% for 2 minutes
# - Database connections > 80% of max
# - API error rate > 1% for 1 minute
# - Queue length > 1000 items
# - Disk space < 10% free
# - SSL certificate expires in < 30 days

# ========================
# Production Backup Strategy
# ========================

# Database Backups:
# - Full backup daily at 2 AM
# - Transaction log backup every 15 minutes
# - Point-in-time recovery capability
# - Cross-region replication
# - 30-day retention policy

# File Backups:
# - User uploads backed up daily
# - Configuration files versioned
# - SSL certificates backed up
# - Application logs archived weekly

# ========================
# Disaster Recovery Plan
# ========================

# RTO (Recovery Time Objective): 1 hour
# RPO (Recovery Point Objective): 15 minutes

# Recovery Steps:
# 1. Assess damage scope
# 2. Activate standby infrastructure
# 3. Restore database from latest backup
# 4. Restore file systems
# 5. Update DNS records
# 6. Verify all services operational
# 7. Monitor for 24 hours

# ========================
# Performance Optimization
# ========================

# Database Optimization:
# - Connection pooling configured
# - Query performance monitoring
# - Index optimization
# - Regular VACUUM operations

# Application Optimization:
# - Redis caching enabled
# - CDN for static assets
# - Gzip compression enabled
# - HTTP/2 support

# Infrastructure Optimization:
# - Auto-scaling configured
# - Load balancing enabled
# - Resource limits set appropriately
# - Health checks optimized

# ========================
# Final Production Checklist
# ========================

# Before going live:
# âœ“ All secrets properly configured
# âœ“ SSL certificates installed and tested
# âœ“ Monitoring and alerting configured
# âœ“ Backup and restore procedures tested
# âœ“ Load testing completed
# âœ“ Security scan completed
# âœ“ Documentation updated
# âœ“ Team trained on operations procedures
# âœ“ Incident response plan in place
# âœ“ Rollback procedures tested
  # Reverse Proxy & Load Balancer
  # ========================
  nginx:
    image: nginx:1.24-alpine
    container_name: ai-content-nginx
    restart: always
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/production.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/ssl:/etc/nginx/ssl:ro
      - ssl-certs:/etc/ssl/certs:ro
      - logs:/var/log/nginx
    networks:
      - ai-content-network
    depends_on:
      - web-dashboard
      - content-engine
      - platform-manager
    healthcheck:
      test: ["CMD", "nginx", "-t"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          memory: 256M
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.nginx.rule=Host(`aicontentfactory.com`)"
      - "traefik.http.routers.nginx.tls=true"
      - "traefik.http.routers.nginx.tls.certresolver=letsencrypt"

  # ========================
  # Database Services
  # ========================
  postgres:
    image: postgres:15-alpine
    container_name: ai-content-postgres
    restart: always
    environment:
      POSTGRES_DB: ${DB_NAME}
      POSTGRES_USER: ${DB_USER}
      POSTGRES_PASSWORD: ${DB_PASSWORD}
      POSTGRES_INITDB_ARGS: "--auth-host=md5"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./database/migrations:/docker-entrypoint-initdb.d:ro
      - logs:/var/log/postgresql
    networks:
      - db-network
    ports:
      - "127.0.0.1:5432:5432"  # Only localhost access
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${DB_USER} -d ${DB_NAME}"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 4G
        reservations:
          memory: 2G
    command:
      - postgres
      - -c
      - max_connections=200
      - -c
      - shared_buffers=256MB
      - -c
      - effective_cache_size=1GB
      - -c
      - work_mem=4MB
      - -c
      - maintenance_work_mem=64MB
      - -c
      - log_statement=all
      - -c
      - log_min_duration_statement=1000
      - -c
      - checkpoint_completion_target=0.9
      - -c
      - wal_buffers=16MB

  redis:
    image: redis:7-alpine
    container_name: ai-content-redis
    restart: always
    command: redis-server --appendonly yes --requirepass ${REDIS_PASSWORD} --maxmemory 1gb --maxmemory-policy allkeys-lru
    volumes:
      - redis_data:/data
      - ./redis/redis.conf:/usr/local/etc/redis/redis.conf:ro
    networks:
      - ai-content-network
    ports:
      - "127.0.0.1:6379:6379"  # Only localhost access
    healthcheck:
      test: ["CMD", "redis-cli", "--raw", "incr", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 1G
        reservations:
          memory: 512M

  # ========================
  # Core Application Services
  # ========================
  trend-monitor:
    image: ai-content-factory/trend-monitor:${DOCKER_IMAGE_TAG:-latest}
    container_name: ai-content-trend-monitor
    restart: always
    env_file:
      - ./config/environment/production.env
    environment:
      - NODE_ENV=production
      - DATABASE_URL=postgresql://${DB_USER}:${DB_PASSWORD}@postgres:5432/${DB_NAME}
      - REDIS_URL=redis://:${REDIS_PASSWORD}@redis:6379/0
    volumes:
      - logs:/var/log/app
    networks:
      - ai-content-network
      - db-network
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    deploy:
      replicas: 2
      resources:
        limits:
          cpus: '1'
          memory: 1G
        reservations:
          memory: 512M
      restart_policy:
        condition: any
        delay: 10s
        max_attempts: 3
        window: 120s

  content-engine:
    image: ai-content-factory/content-engine:${DOCKER_IMAGE_TAG:-latest}
    container_name: ai-content-content-engine
    restart: always
    env_file:
      - ./config/environment/production.env
    environment:
      - NODE_ENV=production
      - DATABASE_URL=postgresql://${DB_USER}:${DB_PASSWORD}@postgres:5432/${DB_NAME}
      - REDIS_URL=redis://:${REDIS_PASSWORD}@redis:6379/0
    volumes:
      - uploads:/app/uploads
      - logs:/var/log/app
    networks:
      - ai-content-network
      - db-network
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    deploy:
      replicas: 3
      resources:
        limits:
          cpus: '2'
          memory: 2G
        reservations:
          memory: 1G
      restart_policy:
        condition: any
        delay: 10s
        max_attempts: 3
        window: 120s

  platform-manager:
    image: ai-content-factory/platform-manager:${DOCKER_IMAGE_TAG:-latest}
    container_name: ai-content-platform-manager
    restart: always
    env_file:
      - ./config/environment/production.env
    environment:
      - NODE_ENV=production
      - DATABASE_URL=postgresql://${DB_USER}:${DB_PASSWORD}@postgres:5432/${DB_NAME}
      - REDIS_URL=redis://:${REDIS_PASSWORD}@redis:6379/0
    volumes:
      - uploads:/app/uploads
      - logs:/var/log/app
    networks:
      - ai-content-network
      - db-network
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    deploy:
      replicas: 2
      resources:
        limits:
          cpus: '1'
          memory: 1G
        reservations:
          memory: 512M
      restart_policy:
        condition: any
        delay: 10s
        max_attempts: 3
        window: 120s

  web-dashboard:
    image: ai-content-factory/web-dashboard:${DOCKER_IMAGE_TAG:-latest}
    container_name: ai-content-web-dashboard
    restart: always
    environment:
      - NODE_ENV=production
      - REACT_APP_API_BASE_URL=${API_BASE_URL}
      - REACT_APP_WS_URL=${WS_URL}
    volumes:
      - logs:/var/log/nginx
    networks:
      - ai-content-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    deploy:
      replicas: 2
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          memory: 256M

  # ========================
  # Workflow Automation
  # ========================
  n8n:
    image: n8nio/n8n:latest
    container_name: ai-content-n8n
    restart: always
    environment:
      - NODE_ENV=production
      - N8N_BASIC_AUTH_ACTIVE=false
      - N8N_JWT_AUTH_ACTIVE=true
      - N8N_JWT_AUTH_HEADER=Authorization
      - N8N_ENCRYPTION_KEY=${N8N_ENCRYPTION_KEY}
      - DB_TYPE=postgresdb
      - DB_POSTGRESDB_HOST=postgres
      - DB_POSTGRESDB_PORT=5432
      - DB_POSTGRESDB_DATABASE=n8n_production
      - DB_POSTGRESDB_USER=${N8N_DB_USER}
      - DB_POSTGRESDB_PASSWORD=${N8N_DB_PASSWORD}
      - DB_POSTGRESDB_SSL_ENABLED=true
      - N8N_PROTOCOL=https
      - N8N_HOST=${N8N_HOST}
      - N8N_PORT=443
      - WEBHOOK_URL=https://workflows.aicontentfactory.com
    volumes:
      - n8n_data:/home/node/.n8n
      - uploads:/data/uploads
      - logs:/var/log/n8n
    networks:
      - ai-content-network
      - db-network
    depends_on:
      postgres:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5678/healthz"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 1G
        reservations:
          memory: 512M

  # ========================
  # Monitoring Stack
  # ========================
  prometheus:
    image: prom/prometheus:latest
    container_name: ai-content-prometheus
    restart: always
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=30d'
      - '--web.enable-lifecycle'
    volumes:
      - ./monitoring/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus_data:/prometheus
    networks:
      - monitoring
      - ai-content-network
    ports:
      - "127.0.0.1:9090:9090"
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:9090/-/healthy"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 1G
        reservations:
          memory: 512M

  grafana:
    image: grafana/grafana:latest
    container_name: ai-content-grafana
    restart: always
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD}
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_SERVER_DOMAIN=${GRAFANA_DOMAIN}
      - GF_SERVER_ROOT_URL=https://${GRAFANA_DOMAIN}
      - GF_SECURITY_COOKIE_SECURE=true
      - GF_SECURITY_STRICT_TRANSPORT_SECURITY=true
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana/provisioning:/etc/grafana/provisioning:ro
      - ./monitoring/grafana/dashboards:/var/lib/grafana/dashboards:ro
    networks:
      - monitoring
      - ai-content-network
    ports:
      - "127.0.0.1:3000:3000"
    depends_on:
      - prometheus
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          memory: 256M

  node-exporter:
    image: prom/node-exporter:latest
    container_name: ai-content-node-exporter
    restart: always
    command:
      - '--path.procfs=/host/proc'
      - '--path.sysfs=/host/sys'
      - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)'
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    networks:
      - monitoring
    deploy:
      resources:
        limits:
          cpus: '0.1'
          memory: 128M

  cadvisor:
    image: gcr.io/cadvisor/cadvisor:latest
    container_name: ai-content-cadvisor
    restart: always
    privileged: true
    devices:
      - /dev/kmsg:/dev/kmsg
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:ro
      - /sys:/sys:ro
      - /var/lib/docker:/var/lib/docker:ro
      - /cgroup:/cgroup:ro
    networks:
      - monitoring
    deploy:
      resources:
        limits:
          cpus: '0.2'
          memory: 256M

  # ========================
  # Log Management
  # ========================
  filebeat:
    image: docker.elastic.co/beats/filebeat:8.11.0
    container_name: ai-content-filebeat
    restart: always
    user: root
    volumes:
      - ./monitoring/filebeat/filebeat.yml:/usr/share/filebeat/filebeat.yml:ro
      - logs:/var/log/app:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
    networks:
      - monitoring
    environment:
      - ELASTICSEARCH_HOSTS=${ELASTICSEARCH_HOSTS}
      - ELASTICSEARCH_USERNAME=${ELASTICSEARCH_USERNAME}
      - ELASTICSEARCH_PASSWORD=${ELASTICSEARCH_PASSWORD}
    deploy:
      resources:
        limits:
          cpus: '0.2'
          memory: 256M

  # ========================
  # Backup Service
  # ========================
  backup:
    image: ai-content-factory/backup:${DOCKER_IMAGE_TAG:-latest}
    container_name: ai-content-backup
    restart: "no"  # Run on-demand or via cron
    environment:
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      - AWS_DEFAULT_REGION=${AWS_REGION}
      - BACKUP_S3_BUCKET=${BACKUP_S3_BUCKET}
      - DATABASE_URL=postgresql://${DB_USER}:${DB_PASSWORD}@postgres:5432/${DB_NAME}
    volumes:
      - postgres_data:/backup/postgres:ro
      - uploads:/backup/uploads:ro
      - logs:/var/log/backup
    networks:
      - db-network
    depends_on:
      - postgres
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M

  # ========================