# test_ai_integration.py - ‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÅ‡∏•‡πâ‡∏ß
import asyncio
import os
import sys
from dotenv import load_dotenv

# ‡πÄ‡∏û‡∏¥‡πà‡∏° path ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö import
sys.path.append('content-engine')
sys.path.append('.')

load_dotenv()

async def test_groq_api():
    """‡∏ó‡∏î‡∏™‡∏≠‡∏ö Groq API ‡∏î‡πâ‡∏ß‡∏¢ model ‡πÉ‡∏´‡∏°‡πà"""
    print("üîÑ ‡∏ó‡∏î‡∏™‡∏≠‡∏ö Groq API...")
    
    try:
        from groq import Groq
        client = Groq(api_key=os.getenv('GROQ_API_KEY'))
        
        # ‡∏•‡∏¥‡∏™‡∏ï‡πå models ‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏µ‡πà‡∏ô‡πà‡∏≤‡∏à‡∏∞‡∏¢‡∏±‡∏á‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ
        models_to_try = [
            "llama-3.3-70b-versatile",
            "llama-3.1-70b-versatile", 
            "llama-3.1-8b-instant",
            "mixtral-8x7b-32768",
            "gemma2-9b-it",
            "gemma-7b-it"
        ]
        
        working_model = None
        
        for model in models_to_try:
            try:
                print(f"  üîç ‡∏ó‡∏î‡∏™‡∏≠‡∏ö model: {model}")
                response = client.chat.completions.create(
                    model=model,
                    messages=[
                        {"role": "user", "content": "‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ ‡∏ï‡∏≠‡∏ö‡∏™‡∏±‡πâ‡∏ô‡πÜ ‡∏ß‡πà‡∏≤‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡πÉ‡∏Ñ‡∏£"}
                    ],
                    max_tokens=50
                )
                
                working_model = model
                print(f"‚úÖ Groq API ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡∏î‡πâ‡∏ß‡∏¢ model: {model}")
                print(f"‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö: {response.choices[0].message.content}")
                break
                
            except Exception as e:
                print(f"  ‚ùå Model {model} ‡πÑ‡∏°‡πà‡∏ó‡∏≥‡∏á‡∏≤‡∏ô: {str(e)[:100]}...")
                continue
        
        if working_model:
            return True, working_model
        else:
            print("‚ùå ‡πÑ‡∏°‡πà‡∏°‡∏µ model ‡πÉ‡∏î‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ")
            return False, None
            
    except Exception as e:
        print(f"‚ùå Groq API Connection Error: {e}")
        return False, None

async def test_openai_api():
    """‡∏ó‡∏î‡∏™‡∏≠‡∏ö OpenAI API"""
    print("\nüîÑ ‡∏ó‡∏î‡∏™‡∏≠‡∏ö OpenAI API...")
    
    try:
        import openai
        from openai import OpenAI
        
        client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))
        
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "user", "content": "‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ ‡∏ï‡∏≠‡∏ö‡∏™‡∏±‡πâ‡∏ô‡πÜ ‡∏ß‡πà‡∏≤‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡πÉ‡∏Ñ‡∏£"}
            ],
            max_tokens=50
        )
        
        print("‚úÖ OpenAI API ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ!")
        print(f"‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö: {response.choices[0].message.content}")
        return True
        
    except Exception as e:
        if "insufficient_quota" in str(e):
            print("‚ö†Ô∏è OpenAI quota ‡∏´‡∏°‡∏î (‡πÑ‡∏°‡πà‡∏°‡∏µ credit)")
        elif "invalid_api_key" in str(e):
            print("‚ùå OpenAI API key ‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á")
        else:
            print(f"‚ùå OpenAI API Error: {e}")
        return False

async def test_trend_analysis():
    """‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå trend ‡∏î‡πâ‡∏ß‡∏¢ service ‡πÉ‡∏´‡∏°‡πà"""
    print("\nüîÑ ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå trend...")
    
    try:
        # ‡πÉ‡∏ä‡πâ Groq Service ‡∏ó‡∏µ‡πà‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ï‡πÅ‡∏•‡πâ‡∏ß
        from ai_services.text_ai.groq_service import GroqService
        
        groq = GroqService()
        
        # ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• trend ‡∏ó‡∏î‡∏™‡∏≠‡∏ö
        trend_data = {
            'topic': 'AI ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤ 2024',
            'popularity_score': 85,
            'growth_rate': 23
        }
        
        result = await groq.analyze_trend(trend_data)
        print("‚úÖ ‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå trend ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!")
        print(f"Viral Potential: {result['scores']['viral_potential']}")
        print(f"Content Angles: {result['content_angles']}")
        return True
        
    except Exception as e:
        print(f"‚ùå Trend Analysis Error: {e}")
        return False

async def test_content_generation():
    """‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤"""
    print("\nüîÑ ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤...")
    
    try:
        from ai_services.text_ai.groq_service import GroqService
        
        groq = GroqService()
        
        result = await groq.generate_content_script(
            idea="‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ú‡∏π‡πâ‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°‡πÉ‡∏ô TikTok",
            platform="tiktok"
        )
        
        print("‚úÖ ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!")
        print(f"Title: {result['title']}")
        print(f"Hook: {result['script']['hook']}")
        return True
        
    except Exception as e:
        print(f"‚ùå Content Generation Error: {e}")
        return False

async def main():
    print("üöÄ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ó‡∏î‡∏™‡∏≠‡∏ö AI Integration (‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ï‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô)\n")
    
    # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö API connections
    groq_ok, working_model = await test_groq_api()
    openai_ok = await test_openai_api()
    
    # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö AI services
    trend_ok = False
    content_ok = False
    
    if groq_ok:
        trend_ok = await test_trend_analysis()
        content_ok = await test_content_generation()
    
    print("\nüìä ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö:")
    print(f"Groq API: {'‚úÖ' if groq_ok else '‚ùå'}")
    if groq_ok and working_model:
        print(f"  ‚îî‚îÄ Working Model: {working_model}")
    print(f"OpenAI API: {'‚úÖ' if openai_ok else '‚ùå'}")
    print(f"Trend Analysis: {'‚úÖ' if trend_ok else '‚ùå'}")
    print(f"Content Generation: {'‚úÖ' if content_ok else '‚ùå'}")
    
    if groq_ok or openai_ok:
        print("\nüéâ ‡∏£‡∏∞‡∏ö‡∏ö‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô!")
        print("\nüìù ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ï‡πà‡∏≠‡πÑ‡∏õ:")
        print("1. python main.py")
        print("2. ‡πÄ‡∏õ‡∏¥‡∏î‡πÄ‡∏ö‡∏£‡∏≤‡∏ß‡πå‡πÄ‡∏ã‡∏≠‡∏£‡πå‡πÑ‡∏õ‡∏ó‡∏µ‡πà: http://localhost:5000")
        print("3. ‡∏Å‡∏î‡∏õ‡∏∏‡πà‡∏° 'Collect Trends'")
        print("4. ‡∏î‡∏π AI analysis ‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ")
        
        if groq_ok:
            print(f"\n‚ú® ‡∏£‡∏∞‡∏ö‡∏ö‡∏à‡∏∞‡πÉ‡∏ä‡πâ Groq model: {working_model}")
        
    else:
        print("\n‚ùå ‡πÑ‡∏°‡πà‡∏°‡∏µ AI service ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ")
        print("üí° ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥:")
        print("- ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö API keys ‡πÉ‡∏ô .env")
        print("- ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö internet connection")
        print("- ‡∏•‡∏≠‡∏á‡πÄ‡∏û‡∏¥‡πà‡∏° credit ‡πÉ‡∏ô OpenAI account")

if __name__ == "__main__":
    asyncio.run(main())