"""
Content Generator
Core logic ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏î‡πâ‡∏ß‡∏¢ AI Services
"""

import asyncio
import logging
from typing import List, Dict, Any, Optional, Union, Tuple
from datetime import datetime, timedelta
from dataclasses import dataclass, asdict
import json
import re
from pathlib import Path

from shared.models.content_plan import ContentPlan
from shared.models.content_opportunity import ContentOpportunity
from shared.models.quality_tier import QualityTier
from services.service_registry import ServiceRegistry
from shared.utils.logger import get_logger
from shared.utils.error_handler import handle_errors, ContentGenerationError
from shared.constants.ai_prompts import PromptTemplates


@dataclass
class GenerationRequest:
    """‡∏Ñ‡∏≥‡∏Ç‡∏≠‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤"""
    content_type: str  # "script", "title", "description", "hashtags", "thumbnail_concept"
    context: Dict[str, Any]  # ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ö‡∏£‡∏¥‡∏ö‡∏ó
    quality_tier: QualityTier
    platform: Optional[str] = None
    style_preferences: Optional[Dict[str, Any]] = None
    constraints: Optional[Dict[str, Any]] = None


@dataclass
class GenerationResult:
    """‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤"""
    content_type: str
    generated_content: Any
    quality_score: float  # 0-10
    generation_time: float  # seconds
    ai_service_used: str
    cost_estimate: float  # ‡∏ö‡∏≤‡∏ó
    metadata: Dict[str, Any]
    created_at: datetime


class ContentGenerator:
    """
    Core engine ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏î‡πâ‡∏ß‡∏¢ AI Services
    """
    
    def __init__(self, quality_tier: QualityTier = QualityTier.BUDGET):
        self.quality_tier = quality_tier
        self.logger = get_logger(__name__)
        self.service_registry = ServiceRegistry()
        self.prompt_templates = PromptTemplates()
        
        # Generation settings
        self.generation_settings = self._load_generation_settings()
        
        # Quality control
        self.quality_thresholds = self._load_quality_thresholds()
        
        # Content templates
        self.content_templates = self._load_content_templates()
        
        # Statistics
        self.generation_stats = {
            "total_requests": 0,
            "successful_generations": 0,
            "failed_generations": 0,
            "total_cost": 0.0,
            "average_quality": 0.0
        }

    def _load_generation_settings(self) -> Dict:
        """‡πÇ‡∏´‡∏•‡∏î‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤"""
        return {
            "script": {
                "max_retries": 3,
                "min_word_count": 50,
                "max_word_count": 2000,
                "required_sections": ["hook", "main_content", "cta"],
                "quality_checks": ["readability", "engagement", "structure"]
            },
            "title": {
                "max_retries": 2,
                "min_length": 10,
                "max_length": 100,
                "variations_count": 5,
                "seo_requirements": ["keyword_inclusion", "length_optimization"]
            },
            "description": {
                "max_retries": 2,
                "min_length": 50,
                "max_length": 500,
                "platform_specific": True,
                "include_keywords": True
            },
            "hashtags": {
                "max_retries": 1,
                "min_count": 5,
                "max_count": 30,
                "trending_weight": 0.4,
                "relevance_weight": 0.6
            },
            "thumbnail_concept": {
                "max_retries": 2,
                "style_consistency": True,
                "platform_optimization": True,
                "color_psychology": True
            }
        }

    def _load_quality_thresholds(self) -> Dict:
        """‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û"""
        return {
            QualityTier.BUDGET: {
                "min_quality_score": 6.0,
                "max_generation_time": 30.0,
                "retry_threshold": 5.0
            },
            QualityTier.BALANCED: {
                "min_quality_score": 7.5,
                "max_generation_time": 60.0,
                "retry_threshold": 6.5
            },
            QualityTier.PREMIUM: {
                "min_quality_score": 8.5,
                "max_generation_time": 120.0,
                "retry_threshold": 7.5
            }
        }

    def _load_content_templates(self) -> Dict:
        """‡πÇ‡∏´‡∏•‡∏î template ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤"""
        return {
            "thai_content_patterns": {
                "formal": {
                    "greeting": ["‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö", "‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡πà‡∏∞", "‡∏¢‡∏¥‡∏ô‡∏î‡∏µ‡∏ï‡πâ‡∏≠‡∏ô‡∏£‡∏±‡∏ö"],
                    "transition": ["‡∏ï‡πà‡∏≠‡πÑ‡∏õ", "‡πÉ‡∏ô‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ", "‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡πà‡∏ß‡∏ô‡∏ñ‡∏±‡∏î‡πÑ‡∏õ"],
                    "conclusion": ["‡∏™‡∏£‡∏∏‡∏õ‡πÅ‡∏•‡πâ‡∏ß", "‡πÉ‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î", "‡πÇ‡∏î‡∏¢‡∏£‡∏ß‡∏°‡πÅ‡∏•‡πâ‡∏ß"]
                },
                "casual": {
                    "greeting": ["‡∏ß‡πà‡∏≤‡πÑ‡∏á‡∏Ñ‡∏£‡∏±‡∏ö", "‡∏Æ‡∏≤‡πÇ‡∏´‡∏•‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏ô", "‡∏û‡∏ö‡∏Å‡∏±‡∏ô‡∏≠‡∏µ‡∏Å‡πÅ‡∏•‡πâ‡∏ß"],
                    "transition": ["‡πÅ‡∏•‡πâ‡∏ß‡∏ô‡∏∞", "‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡πÄ‡∏•‡∏¢", "‡∏°‡∏≤‡∏î‡∏π‡∏Å‡∏±‡∏ô‡∏ï‡πà‡∏≠"],
                    "conclusion": ["‡∏Å‡πá‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì‡∏ô‡∏µ‡πâ‡πÅ‡∏´‡∏•‡∏∞", "‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏µ‡πâ‡∏Å‡πà‡∏≠‡∏ô", "‡∏à‡∏ö‡πÅ‡∏•‡πâ‡∏ß‡∏Ñ‡∏£‡∏±‡∏ö"]
                },
                "energetic": {
                    "greeting": ["‡πÑ‡∏Æ‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏ô!", "‡πÄ‡∏Æ‡πâ‡∏¢‡∏¢‡∏¢!", "‡∏°‡∏≤‡πÅ‡∏•‡πâ‡∏ß‡∏ß!"],
                    "transition": ["‡πÑ‡∏õ‡πÄ‡∏•‡∏¢!", "‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ô‡πÄ‡∏•‡∏¢!", "‡∏°‡∏≤‡∏î‡∏π‡∏Å‡∏±‡∏ô!"],
                    "conclusion": ["‡πÄ‡∏à‡πã‡∏á‡∏°‡∏≤‡∏Å!", "‡∏™‡∏∏‡∏î‡∏¢‡∏≠‡∏î!", "‡πÄ‡∏¢‡∏µ‡πà‡∏¢‡∏°‡πÄ‡∏•‡∏¢!"]
                }
            },
            "content_structures": {
                "educational": [
                    "introduction ‚Üí problem ‚Üí solution ‚Üí example ‚Üí conclusion",
                    "hook ‚Üí background ‚Üí main_points ‚Üí practical_tips ‚Üí summary"
                ],
                "entertainment": [
                    "hook ‚Üí buildup ‚Üí climax ‚Üí reaction ‚Üí call_to_action",
                    "surprise ‚Üí explanation ‚Üí demonstration ‚Üí audience_engagement"
                ],
                "tutorial": [
                    "overview ‚Üí requirements ‚Üí step_by_step ‚Üí troubleshooting ‚Üí results",
                    "goal ‚Üí preparation ‚Üí process ‚Üí verification ‚Üí next_steps"
                ],
                "news": [
                    "breaking ‚Üí background ‚Üí analysis ‚Üí implications ‚Üí conclusion",
                    "headline ‚Üí facts ‚Üí context ‚Üí expert_opinion ‚Üí audience_impact"
                ]
            }
        }

    # Core generation methods

    async def generate_script(self, opportunity: ContentOpportunity, 
                            content_plan: ContentPlan) -> GenerationResult:
        """‡∏™‡∏£‡πâ‡∏≤‡∏á script ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤"""
        
        request = GenerationRequest(
            content_type="script",
            context={
                "opportunity": opportunity,
                "content_plan": content_plan,
                "target_audience": opportunity.content_idea.target_audience,
                "content_type": opportunity.content_idea.content_type,
                "duration": opportunity.content_idea.estimated_duration
            },
            quality_tier=self.quality_tier
        )
        
        return await self._generate_with_quality_control(request, self._generate_script_internal)

    async def _generate_script_internal(self, request: GenerationRequest) -> Dict[str, str]:
        """‡∏™‡∏£‡πâ‡∏≤‡∏á script ‡πÅ‡∏ö‡∏ö‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î"""
        
        opportunity = request.context["opportunity"]
        content_plan = request.context["content_plan"]
        
        # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å AI service
        text_ai = self.service_registry.get_service("text_ai", request.quality_tier)
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á prompt
        prompt = self._build_script_prompt(opportunity, content_plan, request)
        
        # Generate script
        response = await text_ai.generate_content(prompt)
        
        # Parse ‡πÅ‡∏•‡∏∞ validate
        script = self._parse_script_response(response)
        script = await self._enhance_script_quality(script, request)
        
        return script

    def _build_script_prompt(self, opportunity: ContentOpportunity, 
                           content_plan: ContentPlan, request: GenerationRequest) -> str:
        """‡∏™‡∏£‡πâ‡∏≤‡∏á prompt ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö script generation"""
        
        settings = self.generation_settings["script"]
        content_type = opportunity.content_idea.content_type
        
        # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å style pattern
        style_patterns = self.content_templates["thai_content_patterns"]
        
        if "formal" in content_plan.style.lower():
            patterns = style_patterns["formal"]
        elif "casual" in content_plan.style.lower():
            patterns = style_patterns["casual"]
        else:
            patterns = style_patterns["energetic"]
        
        # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å structure
        structures = self.content_templates["content_structures"][content_type]
        structure = structures[0]  # ‡πÉ‡∏ä‡πâ structure ‡πÅ‡∏£‡∏Å
        
        prompt = f"""
‡∏™‡∏£‡πâ‡∏≤‡∏á script ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏ï‡∏≤‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ:

== ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô ==
‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠: {opportunity.content_idea.title}
‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó: {content_type}
‡∏Å‡∏•‡∏∏‡πà‡∏°‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢: {opportunity.content_idea.target_audience}
‡∏£‡∏∞‡∏¢‡∏∞‡πÄ‡∏ß‡∏•‡∏≤: {opportunity.content_idea.estimated_duration} ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ
Trend: {opportunity.trend_data.topic}

== ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤ ==
Structure: {structure}
Style: {content_plan.style}
Tone: {patterns}

== ‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢ ==
- ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡πà‡∏≤‡∏™‡∏ô‡πÉ‡∏à‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏ï‡πà‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ‡πÅ‡∏£‡∏Å
- ‡πÉ‡∏´‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå
- ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏Å‡∏±‡∏ö‡∏Å‡∏•‡∏∏‡πà‡∏°‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢
- ‡∏°‡∏µ call-to-action ‡∏ó‡∏µ‡πà‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô

‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏™‡∏£‡πâ‡∏≤‡∏á script ‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö JSON:
{{
  "hook": "‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡πÄ‡∏õ‡∏¥‡∏î‡∏ó‡∏µ‡πà‡∏î‡∏∂‡∏á‡∏î‡∏π‡∏î‡πÉ‡∏à (3-5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ‡πÅ‡∏£‡∏Å)",
  "main_content": "‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏´‡∏•‡∏±‡∏Å‡∏ó‡∏µ‡πà‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç",
  "cta": "call-to-action ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°",
  "transitions": ["‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏™‡πà‡∏ß‡∏ô"],
  "key_points": ["‡∏à‡∏∏‡∏î‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏ô‡πâ‡∏ô"],
  "emotional_hooks": ["‡∏à‡∏∏‡∏î‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå"]
}}

‡∏Ç‡πâ‡∏≠‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°:
- ‡πÉ‡∏ä‡πâ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏Å‡∏±‡∏ö‡∏Å‡∏•‡∏∏‡πà‡∏°‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢
- ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏≥‡∏£‡∏ß‡∏°: {settings['min_word_count']}-{settings['max_word_count']} ‡∏Ñ‡∏≥
- ‡∏´‡∏•‡∏µ‡∏Å‡πÄ‡∏•‡∏µ‡πà‡∏¢‡∏á‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ó‡∏µ‡πà‡∏≠‡∏≤‡∏à‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ç‡∏±‡∏î‡πÅ‡∏¢‡πâ‡∏á
- ‡πÄ‡∏ô‡πâ‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏ó‡∏¢‡πÅ‡∏•‡∏∞‡∏ß‡∏±‡∏í‡∏ô‡∏ò‡∏£‡∏£‡∏°‡∏ó‡πâ‡∏≠‡∏á‡∏ñ‡∏¥‡πà‡∏ô
"""
        
        return prompt.strip()

    def _parse_script_response(self, response: str) -> Dict[str, str]:
        """‡πÅ‡∏¢‡∏Å‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå response ‡∏à‡∏≤‡∏Å AI"""
        
        try:
            # ‡∏•‡∏≠‡∏á‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô JSON ‡∏Å‡πà‡∏≠‡∏ô
            if response.strip().startswith('{'):
                script = json.loads(response)
            else:
                # ‡πÅ‡∏¢‡∏Å‡πÅ‡∏ö‡∏ö manual
                script = self._manual_parse_script(response)
            
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö required fields
            required = ["hook", "main_content", "cta"]
            for field in required:
                if field not in script or not script[field]:
                    script[field] = self._generate_fallback_content(field)
            
            return script
            
        except Exception as e:
            self.logger.warning(f"Failed to parse script response: {e}")
            return self._create_fallback_script()

    def _manual_parse_script(self, response: str) -> Dict[str, str]:
        """‡πÅ‡∏¢‡∏Å‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå script ‡πÅ‡∏ö‡∏ö manual"""
        
        script = {}
        
        # ‡∏´‡∏≤ patterns ‡∏ï‡πà‡∏≤‡∏á‡πÜ
        patterns = {
            "hook": r"hook[\"']?\s*:?\s*[\"']([^\"']+)[\"']?",
            "main_content": r"main[_\s]?content[\"']?\s*:?\s*[\"']([^\"']+)[\"']?",
            "cta": r"cta[\"']?\s*:?\s*[\"']([^\"']+)[\"']?"
        }
        
        for key, pattern in patterns.items():
            match = re.search(pattern, response, re.IGNORECASE | re.DOTALL)
            if match:
                script[key] = match.group(1).strip()
        
        # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠ pattern ‡πÉ‡∏´‡πâ‡πÅ‡∏¢‡∏Å‡∏ï‡∏≤‡∏° line
        if not script:
            lines = response.split('\n')
            current_section = None
            
            for line in lines:
                line = line.strip()
                if any(word in line.lower() for word in ['hook', '‡πÄ‡∏õ‡∏¥‡∏î', '‡πÄ‡∏£‡∏¥‡πà‡∏°']):
                    current_section = 'hook'
                    script[current_section] = line.split(':', 1)[-1].strip()
                elif any(word in line.lower() for word in ['main', '‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤', '‡∏´‡∏•‡∏±‡∏Å']):
                    current_section = 'main_content'
                    script[current_section] = line.split(':', 1)[-1].strip()
                elif any(word in line.lower() for word in ['cta', '‡∏õ‡∏¥‡∏î', '‡πÄ‡∏ä‡∏¥‡∏ç']):
                    current_section = 'cta'
                    script[current_section] = line.split(':', 1)[-1].strip()
                elif line and current_section:
                    script[current_section] += ' ' + line
        
        return script

    def _generate_fallback_content(self, field: str) -> str:
        """‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏™‡∏≥‡∏£‡∏≠‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö field ‡∏ó‡∏µ‡πà‡∏Ç‡∏≤‡∏î‡∏´‡∏≤‡∏¢"""
        
        fallbacks = {
            "hook": "‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏ô! ‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡∏°‡∏µ‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ô‡πà‡∏≤‡∏™‡∏ô‡πÉ‡∏à‡∏°‡∏≤‡πÅ‡∏ä‡∏£‡πå",
            "main_content": "‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏´‡∏•‡∏±‡∏Å‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÉ‡∏´‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ö‡∏±‡∏ô‡πÄ‡∏ó‡∏¥‡∏á‡πÅ‡∏Å‡πà‡∏ú‡∏π‡πâ‡∏ä‡∏°",
            "cta": "‡∏Å‡∏î‡πÑ‡∏•‡∏Ñ‡πå‡πÅ‡∏•‡∏∞‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°‡∏ñ‡πâ‡∏≤‡∏ä‡∏≠‡∏ö‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ô‡∏∞‡∏Ñ‡∏£‡∏±‡∏ö"
        }
        
        return fallbacks.get(field, f"[Missing {field}]")

    def _create_fallback_script(self) -> Dict[str, str]:
        """‡∏™‡∏£‡πâ‡∏≤‡∏á script ‡∏™‡∏≥‡∏£‡∏≠‡∏á‡πÄ‡∏°‡∏∑‡πà‡∏≠ AI ‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß"""
        
        return {
            "hook": "‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏ô! ‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡∏°‡∏µ‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ô‡πà‡∏≤‡∏™‡∏ô‡πÉ‡∏à‡∏°‡∏≤‡πÅ‡∏ä‡∏£‡πå",
            "main_content": "‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏´‡∏•‡∏±‡∏Å‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÉ‡∏´‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ö‡∏±‡∏ô‡πÄ‡∏ó‡∏¥‡∏á‡πÅ‡∏Å‡πà‡∏ú‡∏π‡πâ‡∏ä‡∏° ‡πÇ‡∏î‡∏¢‡∏à‡∏∞‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡πÅ‡∏•‡∏∞‡πÉ‡∏´‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå",
            "cta": "‡∏Å‡∏î‡πÑ‡∏•‡∏Ñ‡πå‡πÅ‡∏•‡∏∞‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°‡∏ñ‡πâ‡∏≤‡∏ä‡∏≠‡∏ö‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ô‡∏∞‡∏Ñ‡∏£‡∏±‡∏ö",
            "transitions": ["‡∏ï‡πà‡∏≠‡πÑ‡∏õ", "‡πÉ‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏µ‡πâ", "‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢"],
            "key_points": ["‡∏à‡∏∏‡∏î‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç", "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏•‡∏±‡∏Å", "‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏Ñ‡∏ß‡∏£‡∏£‡∏π‡πâ"],
            "emotional_hooks": ["‡∏ô‡πà‡∏≤‡∏™‡∏ô‡πÉ‡∏à", "‡∏õ‡∏£‡∏∞‡∏ó‡∏±‡∏ö‡πÉ‡∏à", "‡∏ô‡πà‡∏≤‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°"]
        }

    async def _enhance_script_quality(self, script: Dict[str, str], 
                                    request: GenerationRequest) -> Dict[str, str]:
        """‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û script"""
        
        settings = self.generation_settings["script"]
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß
        script = self._adjust_script_length(script, settings)
        
        # ‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏†‡∏≤‡∏©‡∏≤
        script = await self._improve_language_quality(script, request)
        
        # ‡πÄ‡∏û‡∏¥‡πà‡∏° emotional elements
        script = self._add_emotional_elements(script, request)
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö SEO ‡πÅ‡∏•‡∏∞ keyword
        script = self._optimize_for_keywords(script, request)
        
        return script

    def _adjust_script_length(self, script: Dict[str, str], settings: Dict) -> Dict[str, str]:
        """‡∏õ‡∏£‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß script ‡πÉ‡∏´‡πâ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°"""
        
        total_words = sum(len(text.split()) for text in script.values() if isinstance(text, str))
        
        if total_words < settings["min_word_count"]:
            # ‡∏Ç‡∏¢‡∏≤‡∏¢‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤
            script["main_content"] += " ‡∏ô‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡∏ô‡∏µ‡πâ‡∏¢‡∏±‡∏á‡∏°‡∏µ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡∏ó‡∏µ‡πà‡∏ô‡πà‡∏≤‡∏™‡∏ô‡πÉ‡∏à ‡πÅ‡∏•‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ú‡∏π‡πâ‡∏ä‡∏°"
        elif total_words > settings["max_word_count"]:
            # ‡∏ï‡∏±‡∏î‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤
            words = script["main_content"].split()
            max_main_words = settings["max_word_count"] - len(script["hook"].split()) - len(script["cta"].split())
            script["main_content"] = " ".join(words[:max_main_words])
        
        return script

    async def _improve_language_quality(self, script: Dict[str, str], 
                                      request: GenerationRequest) -> Dict[str, str]:
        """‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏†‡∏≤‡∏©‡∏≤"""
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÑ‡∏ß‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô
        for key, text in script.items():
            if isinstance(text, str):
                # ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏´‡∏°‡∏≤‡∏¢‡∏ß‡∏£‡∏£‡∏Ñ‡∏ï‡∏≠‡∏ô
                text = re.sub(r'\s+', ' ', text)  # ‡∏•‡∏ö space ‡πÄ‡∏Å‡∏¥‡∏ô
                text = re.sub(r'([.!?])\s*([a-zA-Z‡∏Å-‡∏Æ])', r'\1 \2', text)  # ‡πÄ‡∏û‡∏¥‡πà‡∏° space ‡∏´‡∏•‡∏±‡∏á‡∏à‡∏∏‡∏î
                text = text.strip()
                
                script[key] = text
        
        return script

    def _add_emotional_elements(self, script: Dict[str, str], 
                              request: GenerationRequest) -> Dict[str, str]:
        """‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏≠‡∏á‡∏Ñ‡πå‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏ó‡∏≤‡∏á‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå"""
        
        content_type = request.context.get("content_type", "educational")
        
        emotional_enhancers = {
            "educational": ["‡∏ô‡πà‡∏≤‡∏™‡∏ô‡πÉ‡∏à‡∏°‡∏≤‡∏Å", "‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡πÑ‡∏î‡πâ‡∏à‡∏£‡∏¥‡∏á", "‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå‡πÅ‡∏ô‡πà‡∏ô‡∏≠‡∏ô"],
            "entertainment": ["‡∏™‡∏ô‡∏∏‡∏Å‡∏°‡∏≤‡∏Å", "‡∏Æ‡∏≤‡∏™‡∏∏‡∏î‡πÜ", "‡πÅ‡∏à‡πà‡∏°‡πÄ‡∏•‡∏¢"],
            "tutorial": ["‡∏á‡πà‡∏≤‡∏¢‡∏°‡∏≤‡∏Å", "‡∏ó‡∏≥‡∏ï‡∏≤‡∏°‡πÑ‡∏î‡πâ‡πÅ‡∏ô‡πà‡∏ô‡∏≠‡∏ô", "‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏á‡πà‡∏≤‡∏¢"],
            "news": ["‡∏ô‡πà‡∏≤‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°", "‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ó‡πÉ‡∏´‡∏°‡πà", "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç"]
        }
        
        enhancers = emotional_enhancers.get(content_type, emotional_enhancers["educational"])
        
        # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÉ‡∏ô hook
        if not any(word in script["hook"] for word in enhancers):
            script["hook"] += f" {enhancers[0]}!"
        
        return script

    def _optimize_for_keywords(self, script: Dict[str, str], 
                             request: GenerationRequest) -> Dict[str, str]:
        """‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö SEO ‡πÅ‡∏•‡∏∞ keywords"""
        
        opportunity = request.context.get("opportunity")
        if not opportunity:
            return script
        
        keywords = opportunity.trend_data.keywords
        topic = opportunity.trend_data.topic
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ keywords ‡πÉ‡∏ô‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
        main_content = script["main_content"].lower()
        
        for keyword in keywords:
            if keyword.lower() not in main_content:
                # ‡πÄ‡∏û‡∏¥‡πà‡∏° keyword ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥
                script["main_content"] += f" ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö{keyword}‡∏ô‡∏µ‡πâ‡∏°‡∏µ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏ó‡∏µ‡πà‡∏ô‡πà‡∏≤‡∏™‡∏ô‡πÉ‡∏à"
        
        # ‡πÄ‡∏û‡∏¥‡πà‡∏° topic ‡πÉ‡∏ô hook ‡∏´‡∏≤‡∏Å‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ
        if topic.lower() not in script["hook"].lower():
            script["hook"] = f"‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á{topic}! " + script["hook"]
        
        return script

    # Title generation

    async def generate_titles(self, opportunity: ContentOpportunity, 
                            count: int = 5) -> GenerationResult:
        """‡∏™‡∏£‡πâ‡∏≤‡∏á titles ‡∏´‡∏•‡∏≤‡∏¢‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å"""
        
        request = GenerationRequest(
            content_type="title",
            context={
                "opportunity": opportunity,
                "variations_count": count,
                "seo_focus": True
            },
            quality_tier=self.quality_tier
        )
        
        return await self._generate_with_quality_control(request, self._generate_titles_internal)

    async def _generate_titles_internal(self, request: GenerationRequest) -> List[str]:
        """‡∏™‡∏£‡πâ‡∏≤‡∏á titles ‡πÅ‡∏ö‡∏ö‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î"""
        
        opportunity = request.context["opportunity"]
        count = request.context.get("variations_count", 5)
        
        text_ai = self.service_registry.get_service("text_ai", request.quality_tier)
        
        prompt = self._build_title_prompt(opportunity, count)
        response = await text_ai.generate_content(prompt)
        
        titles = self._parse_titles_response(response)
        titles = self._optimize_titles(titles, opportunity)
        
        return titles[:count]

    def _build_title_prompt(self, opportunity: ContentOpportunity, count: int) -> str:
        """‡∏™‡∏£‡πâ‡∏≤‡∏á prompt ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö title generation"""
        
        prompt = f"""
‡∏™‡∏£‡πâ‡∏≤‡∏á {count} titles ‡∏ó‡∏µ‡πà‡πÅ‡∏ï‡∏Å‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ:

‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡πÄ‡∏î‡∏¥‡∏°: {opportunity.content_idea.title}
‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó: {opportunity.content_idea.content_type}
Trend: {opportunity.trend_data.topic}
Keywords: {', '.join(opportunity.trend_data.keywords)}
‡∏Å‡∏•‡∏∏‡πà‡∏°‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢: {opportunity.content_idea.target_audience}

‡∏™‡∏£‡πâ‡∏≤‡∏á titles ‡∏ó‡∏µ‡πà:
1. ‡∏î‡∏∂‡∏á‡∏î‡∏π‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏ô‡πÉ‡∏à‡πÅ‡∏•‡∏∞‡∏Ñ‡∏•‡∏¥‡∏Å
2. ‡∏°‡∏µ SEO ‡∏ó‡∏µ‡πà‡∏î‡∏µ (‡∏£‡∏ß‡∏° keywords)
3. ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏Å‡∏±‡∏ö‡∏Å‡∏•‡∏∏‡πà‡∏°‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢
4. ‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏ô 100 ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£
5. ‡πÉ‡∏ä‡πâ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏ó‡∏µ‡πà‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏á‡πà‡∏≤‡∏¢

‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡πà‡∏î‡∏µ:
- "‡∏ß‡∏¥‡∏ò‡∏µ [‡∏ó‡∏≥‡∏™‡∏¥‡πà‡∏á‡πÉ‡∏î] ‡∏á‡πà‡∏≤‡∏¢‡πÜ ‡∏ó‡∏µ‡πà‡∏ö‡πâ‡∏≤‡∏ô"
- "[‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡πÉ‡∏î] ‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡πÑ‡∏°‡πà‡πÄ‡∏Ñ‡∏¢‡∏£‡∏π‡πâ"
- "‡πÄ‡∏õ‡∏¥‡∏î‡πÄ‡∏ú‡∏¢ [‡∏Ñ‡∏ß‡∏≤‡∏°‡∏•‡∏±‡∏ö] ‡∏Ç‡∏≠‡∏á [‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡πÉ‡∏î]"
- "[‡∏à‡∏≥‡∏ô‡∏ß‡∏ô] ‡∏ß‡∏¥‡∏ò‡∏µ [‡∏ó‡∏≥‡∏™‡∏¥‡πà‡∏á‡πÉ‡∏î] ‡πÅ‡∏ö‡∏ö‡πÇ‡∏õ‡∏£"

‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô JSON array:
["title 1", "title 2", "title 3", ...]
"""
        
        return prompt.strip()

    def _parse_titles_response(self, response: str) -> List[str]:
        """‡πÅ‡∏¢‡∏Å‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå response ‡∏Ç‡∏≠‡∏á titles"""
        
        try:
            if response.strip().startswith('['):
                titles = json.loads(response)
            else:
                # ‡πÅ‡∏¢‡∏Å‡πÅ‡∏ö‡∏ö manual
                lines = response.split('\n')
                titles = []
                for line in lines:
                    line = line.strip()
                    if line and not line.startswith(('#', '//', '/*')):
                        # ‡∏•‡∏ö‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏•‡∏Ç ‡πÅ‡∏•‡∏∞ quote
                        title = re.sub(r'^\d+[\.\)]\s*', '', line)
                        title = title.strip('"\'')
                        if title:
                            titles.append(title)
            
            return titles if titles else self._create_fallback_titles()
            
        except Exception as e:
            self.logger.warning(f"Failed to parse titles response: {e}")
            return self._create_fallback_titles()

    def _create_fallback_titles(self) -> List[str]:
        """‡∏™‡∏£‡πâ‡∏≤‡∏á titles ‡∏™‡∏≥‡∏£‡∏≠‡∏á"""
        
        return [
            "‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ô‡πà‡∏≤‡∏™‡∏ô‡πÉ‡∏à‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡πÑ‡∏°‡πà‡∏Ñ‡∏ß‡∏£‡∏û‡∏•‡∏≤‡∏î",
            "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏°‡∏∏‡∏°‡∏°‡∏≠‡∏á‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì",
            "‡∏ß‡∏¥‡∏ò‡∏µ‡∏á‡πà‡∏≤‡∏¢‡πÜ ‡∏ó‡∏µ‡πà‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏ô‡∏ó‡∏≥‡πÑ‡∏î‡πâ",
            "‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏£‡∏¥‡∏á‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡∏≠‡∏≤‡∏à‡πÑ‡∏°‡πà‡πÄ‡∏Ñ‡∏¢‡∏£‡∏π‡πâ",
            "‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡πÄ‡∏î‡πá‡∏î‡∏ó‡∏µ‡πà‡∏°‡∏∑‡∏≠‡∏≠‡∏≤‡∏ä‡∏µ‡∏û‡πÉ‡∏ä‡πâ"
        ]

    def _optimize_titles(self, titles: List[str], opportunity: ContentOpportunity) -> List[str]:
        """‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á titles ‡πÉ‡∏´‡πâ‡∏î‡∏µ‡∏Ç‡∏∂‡πâ‡∏ô"""
        
        optimized = []
        keywords = opportunity.trend_data.keywords
        
        for title in titles:
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß
            if len(title) > 100:
                title = title[:97] + "..."
            elif len(title) < 10:
                title += " ‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏ß‡∏£‡∏£‡∏π‡πâ"
            
            # ‡πÄ‡∏û‡∏¥‡πà‡∏° keywords ‡∏´‡∏≤‡∏Å‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ
            title_lower = title.lower()
            for keyword in keywords:
                if keyword.lower() not in title_lower:
                    # ‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡πÄ‡∏û‡∏¥‡πà‡∏° keyword ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥
                    if len(title) + len(keyword) < 95:
                        title = f"{keyword}: {title}"
                    break
            
            optimized.append(title)
        
        return optimized

    # Description generation

    async def generate_descriptions(self, opportunity: ContentOpportunity,
                                  platforms: List[str] = None) -> GenerationResult:
        """‡∏™‡∏£‡πâ‡∏≤‡∏á descriptions ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏´‡∏•‡∏≤‡∏¢ platforms"""
        
        request = GenerationRequest(
            content_type="description",
            context={
                "opportunity": opportunity,
                "platforms": platforms or ["youtube", "tiktok"],
                "include_seo": True
            },
            quality_tier=self.quality_tier
        )
        
        return await self._generate_with_quality_control(request, self._generate_descriptions_internal)

    async def _generate_descriptions_internal(self, request: GenerationRequest) -> Dict[str, str]:
        """‡∏™‡∏£‡πâ‡∏≤‡∏á descriptions ‡πÅ‡∏ö‡∏ö‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î"""
        
        opportunity = request.context["opportunity"]
        platforms = request.context.get("platforms", ["youtube"])
        
        text_ai = self.service_registry.get_service("text_ai", request.quality_tier)
        
        descriptions = {}
        
        for platform in platforms:
            prompt = self._build_description_prompt(opportunity, platform)
            response = await text_ai.generate_content(prompt)
            
            description = self._parse_description_response(response, platform)
            description = self._optimize_description(description, platform, opportunity)
            
            descriptions[platform] = description
        
        return descriptions

    def _build_description_prompt(self, opportunity: ContentOpportunity, platform: str) -> str:
        """‡∏™‡∏£‡πâ‡∏≤‡∏á prompt ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö description"""
        
        platform_specs = {
            "youtube": {"max_length": 5000, "style": "detailed, SEO-friendly"},
            "tiktok": {"max_length": 300, "style": "short, catchy"},
            "instagram": {"max_length": 2200, "style": "engaging, hashtag-rich"},
            "facebook": {"max_length": 2000, "style": "conversational, shareable"}
        }
        
        spec = platform_specs.get(platform, platform_specs["youtube"])
        
        prompt = f"""
‡∏™‡∏£‡πâ‡∏≤‡∏á description ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö {platform.upper()} ‡∏ï‡∏≤‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ:

‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠: {opportunity.content_idea.title}
‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó: {opportunity.content_idea.content_type}
Trend: {opportunity.trend_data.topic}
Keywords: {', '.join(opportunity.trend_data.keywords)}
‡∏Å‡∏•‡∏∏‡πà‡∏°‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢: {opportunity.content_idea.target_audience}

‡∏Ç‡πâ‡∏≠‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö {platform}:
- ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏ô {spec['max_length']} ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£
- ‡∏™‡πÑ‡∏ï‡∏•‡πå: {spec['style']}
- ‡∏£‡∏ß‡∏° keywords ‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á
- ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ (SEO)
- ‡∏°‡∏µ call-to-action ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°

‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏Ñ‡∏ß‡∏£‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏î‡πâ‡∏ß‡∏¢:
1. ‡∏™‡∏£‡∏∏‡∏õ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ó‡∏µ‡πà‡∏ô‡πà‡∏≤‡∏™‡∏ô‡πÉ‡∏à
2. ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏ú‡∏π‡πâ‡∏ä‡∏°‡∏à‡∏∞‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö
3. ‡πÄ‡∏ä‡∏¥‡∏ç‡∏ä‡∏ß‡∏ô‡πÉ‡∏´‡πâ engagement (like, share, comment)
4. Hashtags ‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö social media)

‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö:
{self._get_description_template(platform)}

‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏™‡∏£‡πâ‡∏≤‡∏á description ‡∏ó‡∏µ‡πà‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå:
"""
        
        return prompt.strip()

    def _get_description_template(self, platform: str) -> str:
        """‡πÑ‡∏î‡πâ template ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö description ‡πÅ‡∏ï‡πà‡∏•‡∏∞ platform"""
        
        templates = {
            "youtube": """
üéØ ‡πÉ‡∏ô‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏ô‡∏µ‡πâ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡∏û‡∏≤‡∏Ñ‡∏∏‡∏ì‡∏°‡∏≤‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö [‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠]

üìç ‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡∏à‡∏∞‡πÑ‡∏î‡πâ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ:
‚Ä¢ [‡∏à‡∏∏‡∏î‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç 1]
‚Ä¢ [‡∏à‡∏∏‡∏î‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç 2]
‚Ä¢ [‡∏à‡∏∏‡∏î‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç 3]

üîî ‡∏Å‡∏î‡∏Å‡∏£‡∏∞‡∏î‡∏¥‡πà‡∏á‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡∏û‡∏•‡∏≤‡∏î‡∏Ñ‡∏•‡∏¥‡∏õ‡πÉ‡∏´‡∏°‡πà
üëç ‡∏Å‡∏î‡πÑ‡∏•‡∏Ñ‡πå‡∏ñ‡πâ‡∏≤‡∏ä‡∏≠‡∏ö
üí¨ ‡∏Ñ‡∏≠‡∏°‡πÄ‡∏°‡∏ô‡∏ï‡πå‡∏ö‡∏≠‡∏Å‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î‡πÄ‡∏´‡πá‡∏ô

#‡πÅ‡∏Æ‡∏ä‡πÅ‡∏ó‡πá‡∏Å #‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á
""",
            "tiktok": """
[‡∏≠‡∏µ‡πÇ‡∏°‡∏à‡∏¥] [‡∏™‡∏£‡∏∏‡∏õ‡∏™‡∏±‡πâ‡∏ô‡πÜ ‡∏ó‡∏µ‡πà‡∏î‡∏∂‡∏á‡∏î‡∏π‡∏î]

‚ú® [‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå‡∏´‡∏•‡∏±‡∏Å]
üí´ [‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ô‡πà‡∏≤‡∏™‡∏ô‡πÉ‡∏à]

Follow ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏î‡∏µ‡πÜ ‡∏ó‡∏∏‡∏Å‡∏ß‡∏±‡∏ô! 

#fyp #viral #‡πÅ‡∏Æ‡∏ä‡πÅ‡∏ó‡πá‡∏Å
""",
            "instagram": """
[‡∏≠‡∏µ‡πÇ‡∏°‡∏à‡∏¥] [Hook ‡∏ó‡∏µ‡πà‡∏ô‡πà‡∏≤‡∏™‡∏ô‡πÉ‡∏à]

[‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏´‡∏•‡∏±‡∏Å‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå]

üíù Save ‡πÑ‡∏ß‡πâ‡∏î‡∏π‡∏†‡∏∂‡∏Å‡πÑ‡∏î‡πâ
üì± Share ‡πÉ‡∏´‡πâ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ô‡πÜ
üí≠ ‡∏Ñ‡∏≠‡∏°‡πÄ‡∏°‡∏ô‡∏ï‡πå‡∏ö‡∏≠‡∏Å‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î‡πÄ‡∏´‡πá‡∏ô

#‡πÅ‡∏Æ‡∏ä‡πÅ‡∏ó‡πá‡∏Å #instagram #content
""",
            "facebook": """
[‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡πÄ‡∏õ‡∏¥‡∏î‡∏ó‡∏µ‡πà‡∏ô‡πà‡∏≤‡∏™‡∏ô‡πÉ‡∏à]

[‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏´‡∏•‡∏±‡∏Å‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î]

üë• ‡πÅ‡∏ä‡∏£‡πå‡πÉ‡∏´‡πâ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ô‡πÜ ‡∏î‡∏π‡∏Å‡∏±‡∏ô‡∏î‡πâ‡∏ß‡∏¢
‚ù§Ô∏è ‡∏Å‡∏î‡πÑ‡∏•‡∏Ñ‡πå‡∏ñ‡πâ‡∏≤‡πÄ‡∏´‡πá‡∏ô‡∏î‡πâ‡∏ß‡∏¢
üí¨ ‡∏Ñ‡∏≠‡∏°‡πÄ‡∏°‡∏ô‡∏ï‡πå‡πÅ‡∏ö‡πà‡∏á‡∏õ‡∏±‡∏ô‡∏õ‡∏£‡∏∞‡∏™‡∏ö‡∏Å‡∏≤‡∏£‡∏ì‡πå
"""
        }
        
        return templates.get(platform, templates["youtube"])

    def _parse_description_response(self, response: str, platform: str) -> str:
        """‡πÅ‡∏¢‡∏Å‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå response ‡∏Ç‡∏≠‡∏á description"""
        
        # ‡∏•‡∏ö markdown ‡πÅ‡∏•‡∏∞ formatting ‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô
        description = response.strip()
        
        # ‡∏•‡∏ö code blocks
        description = re.sub(r'```[\s\S]*?```', '', description)
        description = re.sub(r'`([^`]+)`', r'\1', description)
        
        # ‡∏•‡∏ö headers ‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô
        description = re.sub(r'^#+\s*', '', description, flags=re.MULTILINE)
        
        # ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î
        description = re.sub(r'\n{3,}', '\n\n', description)
        description = description.strip()
        
        return description

    def _optimize_description(self, description: str, platform: str, 
                            opportunity: ContentOpportunity) -> str:
        """‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á description ‡πÉ‡∏´‡πâ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°"""
        
        platform_specs = {
            "youtube": {"max_length": 5000},
            "tiktok": {"max_length": 300},
            "instagram": {"max_length": 2200},
            "facebook": {"max_length": 2000}
        }
        
        max_length = platform_specs.get(platform, {}).get("max_length", 2000)
        
        # ‡∏ï‡∏±‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡∏´‡∏≤‡∏Å‡πÄ‡∏Å‡∏¥‡∏ô
        if len(description) > max_length:
            description = description[:max_length-3] + "..."
        
        # ‡πÄ‡∏û‡∏¥‡πà‡∏° keywords ‡∏´‡∏≤‡∏Å‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ
        keywords = opportunity.trend_data.keywords
        description_lower = description.lower()
        
        for keyword in keywords:
            if keyword.lower() not in description_lower:
                if len(description) + len(keyword) + 10 < max_length:
                    description += f"\n\n#{keyword.replace(' ', '')}"
        
        return description

    # Hashtags generation

    async def generate_hashtags(self, opportunity: ContentOpportunity,
                              platform: str = "general") -> GenerationResult:
        """‡∏™‡∏£‡πâ‡∏≤‡∏á hashtags ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤"""
        
        request = GenerationRequest(
            content_type="hashtags",
            context={
                "opportunity": opportunity,
                "platform": platform,
                "trending_focus": True
            },
            quality_tier=self.quality_tier
        )
        
        return await self._generate_with_quality_control(request, self._generate_hashtags_internal)

    async def _generate_hashtags_internal(self, request: GenerationRequest) -> List[str]:
        """‡∏™‡∏£‡πâ‡∏≤‡∏á hashtags ‡πÅ‡∏ö‡∏ö‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î"""
        
        opportunity = request.context["opportunity"]
        platform = request.context.get("platform", "general")
        
        text_ai = self.service_registry.get_service("text_ai", request.quality_tier)
        
        prompt = self._build_hashtags_prompt(opportunity, platform)
        response = await text_ai.generate_content(prompt)
        
        hashtags = self._parse_hashtags_response(response)
        hashtags = self._optimize_hashtags(hashtags, platform, opportunity)
        
        return hashtags

    def _build_hashtags_prompt(self, opportunity: ContentOpportunity, platform: str) -> str:
        """‡∏™‡∏£‡πâ‡∏≤‡∏á prompt ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö hashtags"""
        
        platform_limits = {
            "tiktok": 10,
            "instagram": 30,
            "youtube": 15,
            "facebook": 20,
            "general": 15
        }
        
        max_hashtags = platform_limits.get(platform, 15)
        
        prompt = f"""
‡∏™‡∏£‡πâ‡∏≤‡∏á hashtags ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ:

‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠: {opportunity.content_idea.title}
‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó: {opportunity.content_idea.content_type}
Trend: {opportunity.trend_data.topic}
Keywords: {', '.join(opportunity.trend_data.keywords)}
Platform: {platform}

‡∏™‡∏£‡πâ‡∏≤‡∏á {max_hashtags} hashtags ‡∏ó‡∏µ‡πà:
1. ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤
2. ‡∏°‡∏µ‡πÇ‡∏≠‡∏Å‡∏≤‡∏™‡πÄ‡∏õ‡πá‡∏ô trending
3. ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏Å‡∏±‡∏ö {platform}
4. ‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏û‡∏¥‡πà‡∏° reach ‡πÅ‡∏•‡∏∞ engagement
5. ‡πÉ‡∏ä‡πâ‡∏ó‡∏±‡πâ‡∏á‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡πÅ‡∏•‡∏∞‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©

‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó hashtags ‡∏ó‡∏µ‡πà‡∏Ñ‡∏ß‡∏£‡∏°‡∏µ:
- Hashtags ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤ (3-5 tags)
- Hashtags ‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ‡∏Ç‡∏≠‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó (2-3 tags)
- Hashtags trending (2-3 tags)
- Hashtags platform-specific (2-3 tags)
- Hashtags community/audience (2-3 tags)

‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö:
#‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏´‡∏•‡∏±‡∏Å #‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó #trending #platform #community

‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô JSON array:
["#hashtag1", "#hashtag2", "#hashtag3", ...]
"""
        
        return prompt.strip()

    def _parse_hashtags_response(self, response: str) -> List[str]:
        """‡πÅ‡∏¢‡∏Å‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå response ‡∏Ç‡∏≠‡∏á hashtags"""
        
        try:
            if response.strip().startswith('['):
                hashtags = json.loads(response)
            else:
                # ‡πÅ‡∏¢‡∏Å‡πÅ‡∏ö‡∏ö manual
                hashtags = []
                
                # ‡∏´‡∏≤ hashtags ‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
                hash_pattern = r'#[^\s#]+(?=[^\w]|$)'
                matches = re.findall(hash_pattern, response)
                hashtags.extend(matches)
                
                # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠ hashtags ‡πÉ‡∏´‡πâ‡πÅ‡∏¢‡∏Å‡∏à‡∏≤‡∏Å lines
                if not hashtags:
                    lines = response.split('\n')
                    for line in lines:
                        line = line.strip()
                        if line.startswith('#'):
                            hashtags.append(line.split()[0])
            
            # ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î hashtags
            cleaned_hashtags = []
            for tag in hashtags:
                if isinstance(tag, str):
                    tag = tag.strip()
                    if not tag.startswith('#'):
                        tag = '#' + tag
                    tag = re.sub(r'[^\w#‡∏Å-‡∏Æ]', '', tag)
                    if len(tag) > 1:  # ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤ # ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß
                        cleaned_hashtags.append(tag)
            
            return cleaned_hashtags if cleaned_hashtags else self._create_fallback_hashtags()
            
        except Exception as e:
            self.logger.warning(f"Failed to parse hashtags response: {e}")
            return self._create_fallback_hashtags()

    def _create_fallback_hashtags(self) -> List[str]:
        """‡∏™‡∏£‡πâ‡∏≤‡∏á hashtags ‡∏™‡∏≥‡∏£‡∏≠‡∏á"""
        
        return [
            "#‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏î‡∏µ", "#‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ", "#‡∏™‡∏ô‡∏∏‡∏Å‡∏™‡∏ô‡∏≤‡∏ô", "#‡πÑ‡∏ó‡∏¢", "#Thailand",
            "#‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°", "#‡πÅ‡∏ä‡∏£‡πå", "#‡πÑ‡∏•‡∏Ñ‡πå", "#‡πÄ‡∏ó‡∏£‡∏ô‡∏î‡πå", "#viral",
            "#content", "#learning", "#entertainment", "#education", "#trending"
        ]

    def _optimize_hashtags(self, hashtags: List[str], platform: str, 
                         opportunity: ContentOpportunity) -> List[str]:
        """‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á hashtags ‡πÉ‡∏´‡πâ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°"""
        
        platform_limits = {
            "tiktok": 10,
            "instagram": 30,
            "youtube": 15,
            "facebook": 20,
            "general": 15
        }
        
        max_hashtags = platform_limits.get(platform, 15)
        
        # ‡πÄ‡∏û‡∏¥‡πà‡∏° platform-specific hashtags
        platform_tags = {
            "tiktok": ["#fyp", "#viral", "#TikTokThailand"],
            "instagram": ["#instathailand", "#‡∏≠‡∏¥‡∏ô‡∏™‡∏ï‡∏≤‡πÑ‡∏ó‡∏¢"],
            "youtube": ["#YouTubeThailand", "#‡∏Ñ‡∏•‡∏¥‡∏õ‡πÑ‡∏ó‡∏¢"],
            "facebook": ["#‡πÄ‡∏ü‡∏™‡∏ö‡∏∏‡πä‡∏Å", "#‡πÅ‡∏ä‡∏£‡πå"]
        }
        
        if platform in platform_tags:
            for tag in platform_tags[platform]:
                if tag not in hashtags and len(hashtags) < max_hashtags:
                    hashtags.append(tag)
        
        # ‡πÄ‡∏û‡∏¥‡πà‡∏° keywords ‡∏à‡∏≤‡∏Å trend
        for keyword in opportunity.trend_data.keywords:
            keyword_tag = f"#{keyword.replace(' ', '')}"
            if keyword_tag not in hashtags and len(hashtags) < max_hashtags:
                hashtags.append(keyword_tag)
        
        # ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏à‡∏≥‡∏ô‡∏ß‡∏ô
        return hashtags[:max_hashtags]

    # Thumbnail concept generation

    async def generate_thumbnail_concept(self, opportunity: ContentOpportunity,
                                       style_preferences: Dict = None) -> GenerationResult:
        """‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏ô‡∏ß‡∏Ñ‡∏¥‡∏î thumbnail"""
        
        request = GenerationRequest(
            content_type="thumbnail_concept",
            context={
                "opportunity": opportunity,
                "style_preferences": style_preferences or {},
                "platform_optimization": True
            },
            quality_tier=self.quality_tier
        )
        
        return await self._generate_with_quality_control(request, self._generate_thumbnail_internal)

    async def _generate_thumbnail_internal(self, request: GenerationRequest) -> Dict[str, Any]:
        """‡∏™‡∏£‡πâ‡∏≤‡∏á thumbnail concept ‡πÅ‡∏ö‡∏ö‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î"""
        
        opportunity = request.context["opportunity"]
        style_prefs = request.context.get("style_preferences", {})
        
        text_ai = self.service_registry.get_service("text_ai", request.quality_tier)
        
        prompt = self._build_thumbnail_prompt(opportunity, style_prefs)
        response = await text_ai.generate_content(prompt)
        
        concept = self._parse_thumbnail_response(response)
        concept = self._optimize_thumbnail_concept(concept, opportunity)
        
        return concept

    def _build_thumbnail_prompt(self, opportunity: ContentOpportunity, 
                              style_prefs: Dict) -> str:
        """‡∏™‡∏£‡πâ‡∏≤‡∏á prompt ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö thumbnail concept"""
        
        prompt = f"""
‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏ô‡∏ß‡∏Ñ‡∏¥‡∏î thumbnail ‡∏ó‡∏µ‡πà‡∏ô‡πà‡∏≤‡∏Ñ‡∏•‡∏¥‡∏Å‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ:

‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠: {opportunity.content_idea.title}
‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó: {opportunity.content_idea.content_type}
‡∏Å‡∏•‡∏∏‡πà‡∏°‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢: {opportunity.content_idea.target_audience}
Trend: {opportunity.trend_data.topic}

‡∏™‡∏£‡πâ‡∏≤‡∏á thumbnail concept ‡∏ó‡∏µ‡πà:
1. ‡∏î‡∏∂‡∏á‡∏î‡∏π‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏ô‡πÉ‡∏à‡πÅ‡∏•‡∏∞‡πÄ‡∏û‡∏¥‡πà‡∏° click-through rate
2. ‡∏™‡∏∑‡πà‡∏≠‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÑ‡∏î‡πâ‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô
3. ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏Å‡∏±‡∏ö‡∏Å‡∏•‡∏∏‡πà‡∏°‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢
4. ‡πÇ‡∏î‡∏î‡πÄ‡∏î‡πà‡∏ô‡πÉ‡∏ô‡∏ü‡∏µ‡∏î social media
5. ‡πÉ‡∏ä‡πâ‡∏™‡∏µ‡πÅ‡∏•‡∏∞ composition ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°

‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏≠‡∏ö‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö JSON:
{{
  "main_concept": "‡πÅ‡∏ô‡∏ß‡∏Ñ‡∏¥‡∏î‡∏´‡∏•‡∏±‡∏Å‡∏Ç‡∏≠‡∏á‡∏†‡∏≤‡∏û",
  "visual_elements": ["‡∏≠‡∏á‡∏Ñ‡πå‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏†‡∏≤‡∏û 1", "‡∏≠‡∏á‡∏Ñ‡πå‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏†‡∏≤‡∏û 2"],
  "color_scheme": ["‡∏™‡∏µ‡∏´‡∏•‡∏±‡∏Å", "‡∏™‡∏µ‡∏£‡∏≠‡∏á"],
  "text_overlay": {{
    "main_text": "‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏•‡∏±‡∏Å‡∏ö‡∏ô thumbnail",
    "font_style": "‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ü‡∏≠‡∏ô‡∏ï‡πå",
    "text_placement": "‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°"
  }},
  "composition": "‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏≠‡∏á‡∏Ñ‡πå‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö",
  "mood": "‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡∏Ç‡∏≠‡∏á‡∏†‡∏≤‡∏û",
  "style": "‡∏™‡πÑ‡∏ï‡∏•‡πå‡∏Å‡∏≤‡∏£‡∏≠‡∏≠‡∏Å‡πÅ‡∏ö‡∏ö",
  "click_factors": ["‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏Ñ‡∏•‡∏¥‡∏Å 1", "‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏Ñ‡∏•‡∏¥‡∏Å 2"]
}}

‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÅ‡∏ô‡∏ß‡∏Ñ‡∏¥‡∏î‡∏ó‡∏µ‡πà‡∏î‡∏µ:
- ‡πÉ‡∏ä‡πâ contrast ‡∏™‡∏π‡∏á‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÇ‡∏î‡∏î‡πÄ‡∏î‡πà‡∏ô
- ‡∏°‡∏µ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏´‡∏£‡∏∑‡∏≠ expression ‡∏ó‡∏µ‡πà‡∏ô‡πà‡∏≤‡∏™‡∏ô‡πÉ‡∏à
- ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÉ‡∏´‡∏ç‡πà‡πÅ‡∏•‡∏∞‡∏≠‡πà‡∏≤‡∏ô‡∏á‡πà‡∏≤‡∏¢
- ‡πÉ‡∏ä‡πâ‡∏™‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏î‡πÉ‡∏™‡πÅ‡∏•‡∏∞‡∏î‡∏∂‡∏á‡∏î‡∏π‡∏î‡∏™‡∏≤‡∏¢‡∏ï‡∏≤
- ‡∏°‡∏µ visual hierarchy ‡∏ó‡∏µ‡πà‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô
"""
        
        return prompt.strip()

    def _parse_thumbnail_response(self, response: str) -> Dict[str, Any]:
        """‡πÅ‡∏¢‡∏Å‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå response ‡∏Ç‡∏≠‡∏á thumbnail concept"""
        
        try:
            if response.strip().startswith('{'):
                concept = json.loads(response)
            else:
                # ‡∏™‡∏£‡πâ‡∏≤‡∏á concept ‡∏à‡∏≤‡∏Å text
                concept = self._extract_thumbnail_concept(response)
            
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö required fields
            required_fields = ["main_concept", "visual_elements", "color_scheme"]
            for field in required_fields:
                if field not in concept:
                    concept[field] = self._get_default_thumbnail_element(field)
            
            return concept
            
        except Exception as e:
            self.logger.warning(f"Failed to parse thumbnail response: {e}")
            return self._create_fallback_thumbnail_concept()

    def _extract_thumbnail_concept(self, response: str) -> Dict[str, Any]:
        """‡∏™‡∏Å‡∏±‡∏î‡πÅ‡∏ô‡∏ß‡∏Ñ‡∏¥‡∏î thumbnail ‡∏à‡∏≤‡∏Å text response"""
        
        concept = {}
        
        # ‡∏´‡∏≤‡πÅ‡∏ô‡∏ß‡∏Ñ‡∏¥‡∏î‡∏´‡∏•‡∏±‡∏Å
        concept_patterns = [
            r"‡πÅ‡∏ô‡∏ß‡∏Ñ‡∏¥‡∏î[‡∏´‡∏•‡∏±‡∏Å]*:?\s*([^\n]+)",
            r"concept:?\s*([^\n]+)",
            r"‡∏´‡∏•‡∏±‡∏Å:?\s*([^\n]+)"
        ]
        
        for pattern in concept_patterns:
            match = re.search(pattern, response, re.IGNORECASE)
            if match:
                concept["main_concept"] = match.group(1).strip()
                break
        
        # ‡∏´‡∏≤‡∏™‡∏µ
        color_pattern = r"‡∏™‡∏µ[^:]*:?\s*([^\n]+)"
        color_match = re.search(color_pattern, response, re.IGNORECASE)
        if color_match:
            colors = [c.strip() for c in color_match.group(1).split(',')]
            concept["color_scheme"] = colors[:3]  # ‡πÄ‡∏≠‡∏≤‡πÅ‡∏Ñ‡πà 3 ‡∏™‡∏µ‡πÅ‡∏£‡∏Å
        
        # ‡∏´‡∏≤ visual elements
        elements = []
        element_patterns = [
            r"‡∏≠‡∏á‡∏Ñ‡πå‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö[^:]*:?\s*([^\n]+)",
            r"elements?[^:]*:?\s*([^\n]+)"
        ]
        
        for pattern in element_patterns:
            matches = re.findall(pattern, response, re.IGNORECASE)
            for match in matches:
                elements.extend([e.strip() for e in match.split(',')])
        
        concept["visual_elements"] = elements[:5]  # ‡πÄ‡∏≠‡∏≤‡πÅ‡∏Ñ‡πà 5 elements ‡πÅ‡∏£‡∏Å
        
        return concept

    def _get_default_thumbnail_element(self, field: str) -> Any:
        """‡πÑ‡∏î‡πâ element ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö thumbnail"""
        
        defaults = {
            "main_concept": "‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏™‡∏∑‡πà‡∏≠‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô‡πÅ‡∏•‡∏∞‡∏ô‡πà‡∏≤‡∏™‡∏ô‡πÉ‡∏à",
            "visual_elements": ["‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡πÅ‡∏™‡∏î‡∏á‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå", "‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏•‡∏±‡∏Å", "‡∏™‡∏±‡∏ç‡∏•‡∏±‡∏Å‡∏©‡∏ì‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á"],
            "color_scheme": ["‡∏™‡∏µ‡∏ô‡πâ‡∏≥‡πÄ‡∏á‡∏¥‡∏ô", "‡∏™‡∏µ‡∏Ç‡∏≤‡∏ß", "‡∏™‡∏µ‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏á"],
            "text_overlay": {
                "main_text": "‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏´‡∏•‡∏±‡∏Å",
                "font_style": "‡∏ï‡∏±‡∏ß‡∏´‡∏ô‡∏≤, ‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô",
                "text_placement": "‡∏™‡πà‡∏ß‡∏ô‡∏ö‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡∏Å‡∏•‡∏≤‡∏á‡∏†‡∏≤‡∏û"
            },
            "composition": "‡πÉ‡∏ä‡πâ rule of thirds ‡πÅ‡∏•‡∏∞ visual hierarchy",
            "mood": "‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏¥‡∏ï‡∏£ ‡∏ô‡πà‡∏≤‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏ñ‡∏∑‡∏≠ ‡∏ô‡πà‡∏≤‡∏™‡∏ô‡πÉ‡∏à",
            "style": "‡∏™‡∏µ‡∏™‡∏î‡πÉ‡∏™ contrast ‡∏™‡∏π‡∏á ‡∏≠‡πà‡∏≤‡∏ô‡∏á‡πà‡∏≤‡∏¢",
            "click_factors": ["‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏ô‡πà‡∏≤‡∏™‡∏ô‡πÉ‡∏à", "‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏î‡∏∂‡∏á‡∏î‡∏π‡∏î", "‡∏™‡∏µ‡∏ó‡∏µ‡πà‡πÇ‡∏î‡∏î‡πÄ‡∏î‡πà‡∏ô"]
        }
        
        return defaults.get(field, "‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏")

    def _create_fallback_thumbnail_concept(self) -> Dict[str, Any]:
        """‡∏™‡∏£‡πâ‡∏≤‡∏á thumbnail concept ‡∏™‡∏≥‡∏£‡∏≠‡∏á"""
        
        return {
            "main_concept": "‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏™‡∏∑‡πà‡∏≠‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô‡πÅ‡∏•‡∏∞‡∏î‡∏∂‡∏á‡∏î‡∏π‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏ô‡πÉ‡∏à",
            "visual_elements": [
                "‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡πÅ‡∏™‡∏î‡∏á‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°",
                "‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà",
                "‡∏™‡∏±‡∏ç‡∏•‡∏±‡∏Å‡∏©‡∏ì‡πå‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏≠‡∏Ñ‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á",
                "‡∏û‡∏∑‡πâ‡∏ô‡∏´‡∏•‡∏±‡∏á‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏£‡∏ö‡∏Å‡∏ß‡∏ô‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤"
            ],
            "color_scheme": ["‡∏™‡∏µ‡∏ô‡πâ‡∏≥‡πÄ‡∏á‡∏¥‡∏ô", "‡∏™‡∏µ‡∏Ç‡∏≤‡∏ß", "‡∏™‡∏µ‡∏™‡πâ‡∏°"],
            "text_overlay": {
                "main_text": "‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏´‡∏•‡∏±‡∏Å‡∏ó‡∏µ‡πà‡∏≠‡πà‡∏≤‡∏ô‡∏á‡πà‡∏≤‡∏¢",
                "font_style": "‡∏ï‡∏±‡∏ß‡∏´‡∏ô‡∏≤ Sans-serif",
                "text_placement": "‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏î‡πà‡∏ô‡∏ä‡∏±‡∏î"
            },
            "composition": "‡πÉ‡∏ä‡πâ rule of thirds ‡πÅ‡∏•‡∏∞‡∏à‡∏±‡∏î‡∏≠‡∏á‡∏Ñ‡πå‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡πÉ‡∏´‡πâ‡∏™‡∏°‡∏î‡∏∏‡∏•",
            "mood": "‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏¥‡∏ï‡∏£ ‡∏ô‡πà‡∏≤‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏ñ‡∏∑‡∏≠ ‡πÅ‡∏•‡∏∞‡∏ô‡πà‡∏≤‡∏™‡∏ô‡πÉ‡∏à",
            "style": "‡∏™‡∏µ‡∏™‡∏î‡πÉ‡∏™ contrast ‡∏™‡∏π‡∏á ‡∏≠‡πà‡∏≤‡∏ô‡∏á‡πà‡∏≤‡∏¢",
            "click_factors": [
                "‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏´‡∏£‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á‡∏≠‡∏≠‡∏Å‡∏ó‡∏µ‡πà‡∏ô‡πà‡∏≤‡∏™‡∏ô‡πÉ‡∏à",
                "‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏≠‡∏¢‡∏≤‡∏Å‡∏£‡∏π‡πâ",
                "‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏™‡∏µ‡∏ó‡∏µ‡πà‡πÇ‡∏î‡∏î‡πÄ‡∏î‡πà‡∏ô‡πÉ‡∏ô‡∏ü‡∏µ‡∏î"
            ]
        }

    def _optimize_thumbnail_concept(self, concept: Dict[str, Any], 
                                  opportunity: ContentOpportunity) -> Dict[str, Any]:
        """‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á thumbnail concept ‡πÉ‡∏´‡πâ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°"""
        
        content_type = opportunity.content_idea.content_type
        
        # ‡∏õ‡∏£‡∏±‡∏ö mood ‡∏ï‡∏≤‡∏°‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤
        type_moods = {
            "educational": "‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏¥‡∏ï‡∏£ ‡∏ô‡πà‡∏≤‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏ñ‡∏∑‡∏≠ ‡πÉ‡∏´‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ",
            "entertainment": "‡∏™‡∏ô‡∏∏‡∏Å‡∏™‡∏ô‡∏≤‡∏ô ‡πÄ‡∏£‡πâ‡∏≤‡πÉ‡∏à ‡∏ô‡πà‡∏≤‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°",
            "tutorial": "‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏á‡πà‡∏≤‡∏¢ ‡∏ô‡πà‡∏≤‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ",
            "news": "‡∏ô‡πà‡∏≤‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏ñ‡∏∑‡∏≠ ‡∏ó‡∏±‡∏ô‡∏™‡∏°‡∏±‡∏¢ ‡∏°‡∏∑‡∏≠‡∏≠‡∏≤‡∏ä‡∏µ‡∏û"
        }
        
        if content_type in type_moods:
            concept["mood"] = type_moods[content_type]
        
        # ‡∏õ‡∏£‡∏±‡∏ö‡∏™‡∏µ‡∏ï‡∏≤‡∏°‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó
        type_colors = {
            "educational": ["‡∏™‡∏µ‡∏ô‡πâ‡∏≥‡πÄ‡∏á‡∏¥‡∏ô", "‡∏™‡∏µ‡∏Ç‡∏≤‡∏ß", "‡∏™‡∏µ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ß"],
            "entertainment": ["‡∏™‡∏µ‡πÅ‡∏î‡∏á", "‡∏™‡∏µ‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏á", "‡∏™‡∏µ‡∏°‡πà‡∏ß‡∏á"],
            "tutorial": ["‡∏™‡∏µ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ß", "‡∏™‡∏µ‡∏Ç‡∏≤‡∏ß", "‡∏™‡∏µ‡πÄ‡∏ó‡∏≤"],
            "news": ["‡∏™‡∏µ‡πÅ‡∏î‡∏á", "‡∏™‡∏µ‡∏î‡∏≥", "‡∏™‡∏µ‡∏Ç‡∏≤‡∏ß"]
        }
        
        if content_type in type_colors:
            concept["color_scheme"] = type_colors[content_type]
        
        # ‡πÄ‡∏û‡∏¥‡πà‡∏° click factors ‡πÄ‡∏â‡∏û‡∏≤‡∏∞
        concept["click_factors"].append(f"‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏Å‡∏±‡∏ö{content_type}")
        concept["click_factors"].append(f"‡∏î‡∏∂‡∏á‡∏î‡∏π‡∏î{opportunity.content_idea.target_audience}")
        
        return concept

    # Quality control ‡πÅ‡∏•‡∏∞ utility methods

    async def _generate_with_quality_control(self, request: GenerationRequest, 
                                           generator_func) -> GenerationResult:
        """‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏û‡∏£‡πâ‡∏≠‡∏° quality control"""
        
        self.generation_stats["total_requests"] += 1
        start_time = datetime.now()
        
        settings = self.generation_settings.get(request.content_type, {})
        max_retries = settings.get("max_retries", 2)
        threshold = self.quality_thresholds[request.quality_tier]
        
        best_result = None
        best_score = 0.0
        
        for attempt in range(max_retries + 1):
            try:
                # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤
                content = await generator_func(request)
                
                # ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û
                quality_score = self._evaluate_content_quality(content, request)
                
                # ‡∏ñ‡πâ‡∏≤‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏î‡∏µ‡∏û‡∏≠‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡πÄ‡∏•‡∏¢
                if quality_score >= threshold["min_quality_score"]:
                    generation_time = (datetime.now() - start_time).total_seconds()
                    cost = self._calculate_generation_cost(request, generation_time)
                    
                    result = GenerationResult(
                        content_type=request.content_type,
                        generated_content=content,
                        quality_score=quality_score,
                        generation_time=generation_time,
                        ai_service_used=self._get_ai_service_name(request.quality_tier),
                        cost_estimate=cost,
                        metadata={
                            "attempt": attempt + 1,
                            "max_retries": max_retries,
                            "quality_threshold": threshold["min_quality_score"]
                        },
                        created_at=datetime.now()
                    )
                    
                    self.generation_stats["successful_generations"] += 1
                    self.generation_stats["total_cost"] += cost
                    self._update_quality_average(quality_score)
                    
                    return result
                
                # ‡πÄ‡∏Å‡πá‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
                if quality_score > best_score:
                    best_score = quality_score
                    best_result = content
                    
            except Exception as e:
                self.logger.warning(f"Generation attempt {attempt + 1} failed: {e}")
                if attempt == max_retries:
                    self.generation_stats["failed_generations"] += 1
                    raise ContentGenerationError(f"Failed after {max_retries + 1} attempts: {e}")
        
        # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏µ‡πà‡∏ú‡πà‡∏≤‡∏ô‡πÄ‡∏Å‡∏ì‡∏ë‡πå ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
        if best_result:
            generation_time = (datetime.now() - start_time).total_seconds()
            cost = self._calculate_generation_cost(request, generation_time)
            
            result = GenerationResult(
                content_type=request.content_type,
                generated_content=best_result,
                quality_score=best_score,
                generation_time=generation_time,
                ai_service_used=self._get_ai_service_name(request.quality_tier),
                cost_estimate=cost,
                metadata={
                    "attempt": max_retries + 1,
                    "max_retries": max_retries,
                    "quality_threshold": threshold["min_quality_score"],
                    "warning": "Quality below threshold but best available"
                },
                created_at=datetime.now()
            )
            
            self.generation_stats["successful_generations"] += 1
            self.generation_stats["total_cost"] += cost
            self._update_quality_average(best_score)
            
            return result
        
        # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÄ‡∏•‡∏¢
        self.generation_stats["failed_generations"] += 1
        raise ContentGenerationError("Failed to generate any usable content")

    def _evaluate_content_quality(self, content: Any, request: GenerationRequest) -> float:
        """‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤"""
        
        content_type = request.content_type
        score = 5.0  # ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô
        
        if content_type == "script":
            score = self._evaluate_script_quality(content)
        elif content_type == "title":
            score = self._evaluate_titles_quality(content)
        elif content_type == "description":
            score = self._evaluate_descriptions_quality(content)
        elif content_type == "hashtags":
            score = self._evaluate_hashtags_quality(content)
        elif content_type == "thumbnail_concept":
            score = self._evaluate_thumbnail_quality(content)
        
        return min(max(score, 0.0), 10.0)  # ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á 0-10

    def _evaluate_script_quality(self, script: Dict[str, str]) -> float:
        """‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û script"""
        
        score = 5.0
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏£‡∏ö‡∏≠‡∏á‡∏Ñ‡πå‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö
        required_parts = ["hook", "main_content", "cta"]
        missing_parts = [part for part in required_parts if part not in script or not script[part]]
        
        if not missing_parts:
            score += 2.0
        else:
            score -= len(missing_parts) * 1.0
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß
        if "main_content" in script:
            word_count = len(script["main_content"].split())
            if 100 <= word_count <= 500:
                score += 1.0
            elif word_count < 50:
                score -= 1.0
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏†‡∏≤‡∏©‡∏≤
        if "hook" in script:
            hook = script["hook"]
            if any(word in hook for word in ["‡∏ô‡πà‡∏≤‡∏™‡∏ô‡πÉ‡∏à", "‡∏°‡∏≤‡∏î‡∏π", "‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ", "‡πÑ‡∏°‡πà‡πÄ‡∏Ñ‡∏¢‡πÄ‡∏´‡πá‡∏ô"]):
                score += 0.5
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö CTA
        if "cta" in script:
            cta = script["cta"]
            if any(word in cta for word in ["‡πÑ‡∏•‡∏Ñ‡πå", "‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°", "‡πÅ‡∏ä‡∏£‡πå", "‡∏Ñ‡∏≠‡∏°‡πÄ‡∏°‡∏ô‡∏ï‡πå"]):
                score += 0.5
        
        return score

    def _evaluate_titles_quality(self, titles: List[str]) -> float:
        """‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û titles"""
        
        if not titles:
            return 0.0
        
        total_score = 0.0
        
        for title in titles:
            title_score = 5.0
            
            # ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°
            if 20 <= len(title) <= 80:
                title_score += 1.0
            elif len(title) < 10 or len(title) > 100:
                title_score -= 1.0
            
            # ‡∏°‡∏µ keywords ‡∏ô‡πà‡∏≤‡∏™‡∏ô‡πÉ‡∏à
            engaging_words = ["‡∏ß‡∏¥‡∏ò‡∏µ", "‡πÄ‡∏Ñ‡∏•‡πá‡∏î‡∏•‡∏±‡∏ö", "‡∏Ñ‡∏ß‡∏≤‡∏°‡∏•‡∏±‡∏ö", "‡πÑ‡∏°‡πà‡πÄ‡∏Ñ‡∏¢‡πÄ‡∏´‡πá‡∏ô", "‡∏ô‡πà‡∏≤‡∏™‡∏ô‡πÉ‡∏à", "‡πÄ‡∏à‡πã‡∏á", "‡∏™‡∏∏‡∏î‡∏¢‡∏≠‡∏î"]
            if any(word in title for word in engaging_words):
                title_score += 1.0
            
            # ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡∏û‡∏¥‡πÄ‡∏®‡∏©‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ
            special_chars = len([c for c in title if not c.isalnum() and c not in " .-"])
            if special_chars <= 3:
                title_score += 0.5
            
            total_score += title_score
        
        return total_score / len(titles)

    def _evaluate_descriptions_quality(self, descriptions: Dict[str, str]) -> float:
        """‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û descriptions"""
        
        if not descriptions:
            return 0.0
        
        total_score = 0.0
        
        for platform, description in descriptions.items():
            desc_score = 5.0
            
            # ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°
            if 50 <= len(description) <= 1000:
                desc_score += 1.0
            elif len(description) < 30:
                desc_score -= 1.0
            
            # ‡∏°‡∏µ call-to-action
            cta_words = ["‡πÑ‡∏•‡∏Ñ‡πå", "‡πÅ‡∏ä‡∏£‡πå", "‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°", "‡∏Ñ‡∏≠‡∏°‡πÄ‡∏°‡∏ô‡∏ï‡πå", "‡∏Å‡∏î", "Subscribe"]
            if any(word in description for word in cta_words):
                desc_score += 1.0
            
            # ‡∏°‡∏µ hashtags (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö social media)
            if platform in ["instagram", "tiktok", "facebook"]:
                if "#" in description:
                    desc_score += 0.5
            
            # ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏î‡∏µ (‡∏°‡∏µ‡∏¢‡πà‡∏≠‡∏´‡∏ô‡πâ‡∏≤)
            if "\n" in description:
                desc_score += 0.5
            
            total_score += desc_score
        
        return total_score / len(descriptions)

    def _evaluate_hashtags_quality(self, hashtags: List[str]) -> float:
        """‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û hashtags"""
        
        if not hashtags:
            return 0.0
        
        score = 5.0
        
        # ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°
        if 5 <= len(hashtags) <= 20:
            score += 1.0
        elif len(hashtags) < 3:
            score -= 2.0
        
        # ‡∏°‡∏µ # ‡∏Ñ‡∏£‡∏ö
        proper_hashtags = [tag for tag in hashtags if tag.startswith('#') and len(tag) > 1]
        if len(proper_hashtags) == len(hashtags):
            score += 1.0
        else:
            score -= 0.5
        
        # ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏•‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢ (‡πÑ‡∏°‡πà‡∏ã‡πâ‡∏≥)
        unique_hashtags = len(set(hashtags))
        if unique_hashtags == len(hashtags):
            score += 1.0
        else:
            score -= 0.5
        
        # ‡∏°‡∏µ‡∏ó‡∏±‡πâ‡∏á‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡πÅ‡∏•‡∏∞‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©
        thai_tags = [tag for tag in hashtags if any('‡∏Å' <= c <= '‡∏Æ' for c in tag)]
        eng_tags = [tag for tag in hashtags if any('a' <= c.lower() <= 'z' for c in tag)]
        
        if thai_tags and eng_tags:
            score += 1.0
        
        return score

    def _evaluate_thumbnail_quality(self, concept: Dict[str, Any]) -> float:
        """‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û thumbnail concept"""
        
        score = 5.0
        
        required_fields = ["main_concept", "visual_elements", "color_scheme"]
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏£‡∏ö‡∏≠‡∏á‡∏Ñ‡πå‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö
        for field in required_fields:
            if field in concept and concept[field]:
                score += 1.0
            else:
                score -= 1.0
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö visual elements
        if "visual_elements" in concept:
            elements = concept["visual_elements"]
            if isinstance(elements, list) and len(elements) >= 3:
                score += 1.0
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö color scheme
        if "color_scheme" in concept:
            colors = concept["color_scheme"]
            if isinstance(colors, list) and len(colors) >= 2:
                score += 1.0
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö click factors
        if "click_factors" in concept:
            factors = concept["click_factors"]
            if isinstance(factors, list) and len(factors) >= 2:
                score += 0.5
        
        return score

    def _calculate_generation_cost(self, request: GenerationRequest, 
                                 generation_time: float) -> float:
        """‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏ï‡πâ‡∏ô‡∏ó‡∏∏‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á"""
        
        base_costs = {
            QualityTier.BUDGET: 2.0,
            QualityTier.BALANCED: 8.0,
            QualityTier.PREMIUM: 25.0
        }
        
        base_cost = base_costs.get(request.quality_tier, 5.0)
        
        # ‡∏õ‡∏£‡∏±‡∏ö‡∏ï‡∏≤‡∏°‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤
        type_multipliers = {
            "script": 2.0,
            "title": 0.5,
            "description": 1.0,
            "hashtags": 0.3,
            "thumbnail_concept": 1.5
        }
        
        multiplier = type_multipliers.get(request.content_type, 1.0)
        
        # ‡∏õ‡∏£‡∏±‡∏ö‡∏ï‡∏≤‡∏°‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ
        time_factor = 1.0 + (generation_time / 60.0)  # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ï‡∏≤‡∏°‡∏ô‡∏≤‡∏ó‡∏µ
        
        total_cost = base_cost * multiplier * time_factor
        
        return round(total_cost, 2)

    def _get_ai_service_name(self, quality_tier: QualityTier) -> str:
        """‡πÑ‡∏î‡πâ‡∏ä‡∏∑‡πà‡∏≠ AI service ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ"""
        
        service_names = {
            QualityTier.BUDGET: "Groq",
            QualityTier.BALANCED: "OpenAI GPT-3.5",
            QualityTier.PREMIUM: "Claude"
        }
        
        return service_names.get(quality_tier, "Unknown AI")

    def _update_quality_average(self, quality_score: float):
        """‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ó‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢"""
        
        total_generations = self.generation_stats["successful_generations"]
        
        if total_generations == 1:
            self.generation_stats["average_quality"] = quality_score
        else:
            current_avg = self.generation_stats["average_quality"]
            new_avg = ((current_avg * (total_generations - 1)) + quality_score) / total_generations
            self.generation_stats["average_quality"] = round(new_avg, 2)

    # Public utility methods

    def get_generation_statistics(self) -> Dict[str, Any]:
        """‡∏î‡∏π‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤"""
        
        stats = self.generation_stats.copy()
        
        if stats["total_requests"] > 0:
            stats["success_rate"] = round(
                (stats["successful_generations"] / stats["total_requests"]) * 100, 2
            )
        else:
            stats["success_rate"] = 0.0
        
        stats["quality_tier"] = self.quality_tier.value
        stats["average_cost_per_generation"] = (
            round(stats["total_cost"] / max(stats["successful_generations"], 1), 2)
        )
        
        return stats

    async def batch_generate_content(self, requests: List[GenerationRequest]) -> List[GenerationResult]:
        """‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏´‡∏•‡∏≤‡∏¢‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ô"""
        
        self.logger.info(f"Starting batch generation for {len(requests)} requests")
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á tasks
        tasks = []
        for request in requests:
            if request.content_type == "script":
                task = self._generate_with_quality_control(request, self._generate_script_internal)
            elif request.content_type == "title":
                task = self._generate_with_quality_control(request, self._generate_titles_internal)
            elif request.content_type == "description":
                task = self._generate_with_quality_control(request, self._generate_descriptions_internal)
            elif request.content_type == "hashtags":
                task = self._generate_with_quality_control(request, self._generate_hashtags_internal)
            elif request.content_type == "thumbnail_concept":
                task = self._generate_with_quality_control(request, self._generate_thumbnail_internal)
            else:
                continue
            
            tasks.append(task)
        
        # ‡∏£‡∏±‡∏ô parallel
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # ‡πÅ‡∏¢‡∏Å results ‡πÅ‡∏•‡∏∞ errors
        successful_results = []
        errors = []
        
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                errors.append({
                    "request_index": i,
                    "content_type": requests[i].content_type,
                    "error": str(result)
                })
            else:
                successful_results.append(result)
        
        if errors:
            self.logger.warning(f"Batch generation completed with {len(errors)} errors")
        
        self.logger.info(f"Batch generation completed: {len(successful_results)} successful")
        
        return successful_results

    def reset_statistics(self):
        """‡∏£‡∏µ‡πÄ‡∏ã‡πá‡∏ï‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥"""
        
        self.generation_stats = {
            "total_requests": 0,
            "successful_generations": 0,
            "failed_generations": 0,
            "total_cost": 0.0,
            "average_quality": 0.0
        }


# Utility functions ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô

async def generate_complete_content_package(opportunity: ContentOpportunity,
                                          quality_tier: QualityTier = QualityTier.BUDGET,
                                          platforms: List[str] = None) -> Dict[str, GenerationResult]:
    """
    ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏Ñ‡∏£‡∏ö‡∏ä‡∏∏‡∏î‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö opportunity
    """
    
    generator = ContentGenerator(quality_tier)
    platforms = platforms or ["youtube"]
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á content plan mock
    content_plan = ContentPlan(
        title=opportunity.content_idea.title,
        description=opportunity.content_idea.description,
        content_type=opportunity.content_idea.content_type,
        target_audience=opportunity.content_idea.target_audience,
        estimated_duration=opportunity.content_idea.estimated_duration,
        style="casual",
        platforms=platforms
    )
    
    results = {}
    
    try:
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á script
        results["script"] = await generator.generate_script(opportunity, content_plan)
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á titles
        results["titles"] = await generator.generate_titles(opportunity, count=5)
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á descriptions
        results["descriptions"] = await generator.generate_descriptions(opportunity, platforms)
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á hashtags
        results["hashtags"] = await generator.generate_hashtags(opportunity, platforms[0])
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á thumbnail concept
        results["thumbnail"] = await generator.generate_thumbnail_concept(opportunity)
        
        return results
        
    except Exception as e:
        logging.error(f"Failed to generate complete content package: {e}")
        raise


if __name__ == "__main__":
    # ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô
    async def example_usage():
        from shared.models.content_opportunity import ContentOpportunity
        from shared.models.trend_data import TrendData
        from services.opportunity_engine import ContentIdea
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á mock data
        trend_data = TrendData(
            id="trend_001",
            source="youtube",
            topic="AI ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏•‡∏¥‡∏õ",
            keywords=["AI", "‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠", "‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ", "‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤"],
            popularity_score=85.0,
            growth_rate=30.0,
            category="technology",
            region="TH",
            collected_at=datetime.now(),
            raw_data={}
        )
        
        content_idea = ContentIdea(
            title="‡∏™‡∏≠‡∏ô‡πÉ‡∏ä‡πâ AI ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏•‡∏¥‡∏õ‡πÑ‡∏ß‡∏£‡∏±‡∏•‡∏á‡πà‡∏≤‡∏¢‡πÜ ‡∏ó‡∏µ‡πà‡∏ö‡πâ‡∏≤‡∏ô",
            description="‡∏Ñ‡∏π‡πà‡∏°‡∏∑‡∏≠‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ AI ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠",
            content_type="educational",
            angle="‡∏°‡∏∏‡∏°‡∏°‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡πÉ‡∏´‡∏°‡πà",
            target_audience="‡∏ô‡∏±‡∏Å‡πÄ‡∏£‡∏µ‡∏¢‡∏ô ‡∏ô‡∏±‡∏Å‡∏®‡∏∂‡∏Å‡∏©‡∏≤ ‡∏Ñ‡∏ô‡∏£‡∏∏‡πà‡∏ô‡πÉ‡∏´‡∏°‡πà",
            estimated_duration=300,
            production_complexity="medium",
            viral_potential=8.5,
            monetization_potential=7.5
        )
        
        opportunity = ContentOpportunity(
            id="opp_001",
            trend_id="trend_001",
            trend_data=trend_data,
            content_idea=content_idea,
            market_analysis=None,
            estimated_roi=4.2,
            production_cost=85.0,
            competition_level="medium",
            priority_score=8.8,
            created_at=datetime.now(),
            status="pending"
        )
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏Ñ‡∏£‡∏ö‡∏ä‡∏∏‡∏î
        print("üöÄ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏Ñ‡∏£‡∏ö‡∏ä‡∏∏‡∏î...")
        
        results = await generate_complete_content_package(
            opportunity,
            quality_tier=QualityTier.BALANCED,
            platforms=["youtube", "tiktok"]
        )
        
        print("‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÄ‡∏™‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß!")
        
        # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
        for content_type, result in results.items():
            print(f"\nüìã {content_type.upper()}:")
            print(f"   Quality Score: {result.quality_score}/10")
            print(f"   Generation Time: {result.generation_time:.2f}s")
            print(f"   Cost: {result.cost_estimate} ‡∏ö‡∏≤‡∏ó")
            print(f"   AI Service: {result.ai_service_used}")
            
            if content_type == "script":
                script = result.generated_content
                print(f"   Hook: {script['hook'][:50]}...")
                print(f"   Main Content: {len(script['main_content'])} characters")
            elif content_type == "titles":
                titles = result.generated_content
                print(f"   Generated {len(titles)} titles")
                print(f"   Best Title: {titles[0]}")
            elif content_type == "descriptions":
                descriptions = result.generated_content
                print(f"   Platforms: {list(descriptions.keys())}")
            elif content_type == "hashtags":
                hashtags = result.generated_content
                print(f"   Generated {len(hashtags)} hashtags")
                print(f"   Sample: {', '.join(hashtags[:5])}")
            elif content_type == "thumbnail":
                concept = result.generated_content
                print(f"   Concept: {concept['main_concept'][:50]}...")
        
        # ‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏£‡∏ß‡∏°
        generator = ContentGenerator(QualityTier.BALANCED)
        stats = generator.get_generation_statistics()
        print(f"\nüìä Generation Statistics:")
        print(f"   Success Rate: {stats['success_rate']}%")
        print(f"   Average Quality: {stats['average_quality']}/10")
        print(f"   Total Cost: {stats['total_cost']} ‡∏ö‡∏≤‡∏ó")
    
    # ‡∏£‡∏±‡∏ô example
    asyncio.run(example_usage())