import os
import json
import sys
from datetime import datetime

# ‡πÄ‡∏û‡∏¥‡πà‡∏° path ‡πÄ‡∏û‡∏∑‡πà‡∏≠ import ‡∏à‡∏≤‡∏Å database
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

class AITrendAnalyzer:
    def __init__(self, ai_service='mock'):
        self.ai_service = ai_service
        self.groq_api_key = os.getenv('GROQ_API_KEY')
        
    def analyze_trend_potential(self, trend_data):
        """‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏®‡∏±‡∏Å‡∏¢‡∏†‡∏≤‡∏û‡∏Ç‡∏≠‡∏á trend ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡∏£‡πâ‡∏≤‡∏á content"""
        if self.ai_service == 'groq' and self.groq_api_key:
            return self.analyze_with_groq(trend_data)
        else:
            return self.analyze_with_mock(trend_data)
    
    def analyze_with_groq(self, trend_data):
        """‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏î‡πâ‡∏ß‡∏¢ Groq AI"""
        try:
            import requests
            
            prompt = self.create_analysis_prompt(trend_data)
            
            headers = {
                'Authorization': f'Bearer {self.groq_api_key}',
                'Content-Type': 'application/json'
            }
            
            payload = {
                'model': 'mixtral-8x7b-32768',
                'messages': [
                    {
                        'role': 'system',
                        'content': 'You are an expert content strategist analyzing trends for content creation opportunities.'
                    },
                    {
                        'role': 'user',
                        'content': prompt
                    }
                ],
                'temperature': 0.7,
                'max_tokens': 1000
            }
            
            response = requests.post(
                'https://api.groq.com/openai/v1/chat/completions',
                headers=headers,
                json=payload
            )
            
            if response.status_code == 200:
                result = response.json()
                analysis_text = result['choices'][0]['message']['content']
                return self.parse_ai_analysis(analysis_text, trend_data)
            else:
                print(f"‚ùå Groq API error: {response.status_code}")
                return self.analyze_with_mock(trend_data)
                
        except Exception as e:
            print(f"‚ùå Error with Groq analysis: {e}")
            return self.analyze_with_mock(trend_data)
    
    def analyze_with_mock(self, trend_data):
        """‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏î‡πâ‡∏ß‡∏¢ logic ‡πÅ‡∏ö‡∏ö‡∏á‡πà‡∏≤‡∏¢ (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏î‡∏™‡∏≠‡∏ö)"""
        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏ï‡πà‡∏≤‡∏á‡πÜ ‡∏ï‡∏≤‡∏° logic ‡πÅ‡∏ö‡∏ö‡∏á‡πà‡∏≤‡∏¢
        viral_potential = self.calculate_viral_potential(trend_data)
        content_saturation = self.calculate_content_saturation(trend_data)
        audience_interest = self.calculate_audience_interest(trend_data)
        monetization_opportunity = self.calculate_monetization_opportunity(trend_data)
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á content angles
        content_angles = self.generate_content_angles(trend_data)
        
        analysis = {
            'trend_id': trend_data.get('id'),
            'trend_topic': trend_data['topic'],
            'scores': {
                'viral_potential': viral_potential,
                'content_saturation': content_saturation,
                'audience_interest': audience_interest,
                'monetization_opportunity': monetization_opportunity,
                'overall_score': (viral_potential + audience_interest + monetization_opportunity - content_saturation) / 3
            },
            'content_angles': content_angles,
            'recommendations': self.generate_recommendations(viral_potential, content_saturation, audience_interest, monetization_opportunity),
            'estimated_metrics': {
                'potential_views': self.estimate_views(trend_data),
                'competition_level': self.assess_competition(trend_data),
                'production_difficulty': self.assess_production_difficulty(trend_data)
            },
            'analyzed_at': datetime.utcnow().isoformat()
        }
        
        print(f"‚úÖ Analyzed trend: {trend_data['topic']} (Score: {analysis['scores']['overall_score']:.1f})")
        return analysis
    
    def create_analysis_prompt(self, trend_data):
        """‡∏™‡∏£‡πâ‡∏≤‡∏á prompt ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö AI"""
        return f"""
        Analyze this trending topic for content creation opportunities:
        
        Topic: {trend_data['topic']}
        Source: {trend_data['source']}
        Current popularity: {trend_data['popularity_score']}
        Growth rate: {trend_data['growth_rate']}%
        Keywords: {', '.join(trend_data.get('keywords', []))}
        Category: {trend_data.get('category', 'General')}
        
        Please rate each aspect from 1-10 and provide analysis:
        
        1. Viral Potential: How likely is this to go viral?
        2. Content Saturation: How much competition exists?
        3. Audience Interest: How engaged is the audience?
        4. Monetization Opportunity: How profitable could this be?
        
        Also suggest 3 unique content angles and provide recommendations.
        
        Format your response as JSON with these keys:
        - viral_potential (1-10)
        - content_saturation (1-10, higher = more saturated)
        - audience_interest (1-10)
        - monetization_opportunity (1-10)
        - content_angles (array of 3 strings)
        - recommendations (string)
        """
    
    def parse_ai_analysis(self, analysis_text, trend_data):
        """‡πÅ‡∏õ‡∏•‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏à‡∏≤‡∏Å AI ‡πÄ‡∏õ‡πá‡∏ô structured data"""
        try:
            # ‡∏•‡∏≠‡∏á‡πÅ‡∏õ‡∏•‡∏á JSON ‡∏ñ‡πâ‡∏≤ AI ‡∏™‡πà‡∏á‡∏°‡∏≤‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö JSON
            analysis_json = json.loads(analysis_text)
            
            return {
                'trend_id': trend_data.get('id'),
                'trend_topic': trend_data['topic'],
                'scores': {
                    'viral_potential': analysis_json.get('viral_potential', 5),
                    'content_saturation': analysis_json.get('content_saturation', 5),
                    'audience_interest': analysis_json.get('audience_interest', 5),
                    'monetization_opportunity': analysis_json.get('monetization_opportunity', 5),
                    'overall_score': (
                        analysis_json.get('viral_potential', 5) + 
                        analysis_json.get('audience_interest', 5) + 
                        analysis_json.get('monetization_opportunity', 5) - 
                        analysis_json.get('content_saturation', 5)
                    ) / 3
                },
                'content_angles': analysis_json.get('content_angles', []),
                'recommendations': analysis_json.get('recommendations', ''),
                'analyzed_at': datetime.utcnow().isoformat()
            }
            
        except json.JSONDecodeError:
            # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà JSON ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ mock analysis
            return self.analyze_with_mock(trend_data)
    
    def calculate_viral_potential(self, trend_data):
        """‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏®‡∏±‡∏Å‡∏¢‡∏†‡∏≤‡∏û‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏£‡πà‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢"""
        score = 5  # base score
        
        # ‡∏õ‡∏£‡∏±‡∏ö‡∏ï‡∏≤‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡∏¥‡∏¢‡∏°
        if trend_data['popularity_score'] > 80:
            score += 2
        elif trend_data['popularity_score'] > 60:
            score += 1
        
        # ‡∏õ‡∏£‡∏±‡∏ö‡∏ï‡∏≤‡∏° growth rate
        if trend_data['growth_rate'] > 20:
            score += 2
        elif trend_data['growth_rate'] > 10:
            score += 1
        
        # ‡∏õ‡∏£‡∏±‡∏ö‡∏ï‡∏≤‡∏° keywords
        viral_keywords = ['ai', 'tutorial', 'hack', 'secret', 'amazing', 'new']
        keyword_matches = sum(1 for kw in trend_data.get('keywords', []) 
                             if any(viral in kw.lower() for viral in viral_keywords))
        score += min(keyword_matches, 2)
        
        return min(score, 10)
    
    def calculate_content_saturation(self, trend_data):
        """‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏≠‡∏¥‡πà‡∏°‡∏ï‡∏±‡∏ß‡∏Ç‡∏≠‡∏á‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤"""
        # ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÅ‡∏ö‡∏ö‡∏á‡πà‡∏≤‡∏¢
        # ‡πÉ‡∏ô‡∏≠‡∏ô‡∏≤‡∏Ñ‡∏ï‡∏≠‡∏≤‡∏à‡πÉ‡∏ä‡πâ API ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏ä‡πá‡∏Ñ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô content ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà
        
        base_saturation = 5
        
        # ‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏ó‡∏µ‡πà‡∏ô‡∏¥‡∏¢‡∏°‡∏°‡∏±‡∏Å‡∏à‡∏∞‡∏≠‡∏¥‡πà‡∏°‡∏ï‡∏±‡∏ß‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤
        popular_topics = ['tutorial', 'review', 'unboxing']
        if any(topic in trend_data['topic'].lower() for topic in popular_topics):
            base_saturation += 2
        
        # Source ‡∏ó‡∏µ‡πà‡∏°‡∏µ competition ‡∏™‡∏π‡∏á
        if trend_data['source'] == 'youtube':
            base_saturation += 1
        
        return min(base_saturation, 10)
    
    def calculate_audience_interest(self, trend_data):
        """‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏ô‡πÉ‡∏à‡∏Ç‡∏≠‡∏á‡∏ú‡∏π‡πâ‡∏ä‡∏°"""
        score = trend_data['popularity_score'] / 10  # ‡πÅ‡∏õ‡∏•‡∏á‡∏à‡∏≤‡∏Å 0-100 ‡πÄ‡∏õ‡πá‡∏ô 0-10
        
        # ‡∏õ‡∏£‡∏±‡∏ö‡∏ï‡∏≤‡∏° raw data
        raw_data = trend_data.get('raw_data', {})
        if 'likes' in raw_data and 'views' in raw_data:
            if raw_data['views'] > 0:
                engagement_rate = raw_data['likes'] / raw_data['views']
                if engagement_rate > 0.05:  # 5% engagement ‡∏î‡∏µ
                    score += 1
        
        return min(score, 10)
    
    def calculate_monetization_opportunity(self, trend_data):
        """‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÇ‡∏≠‡∏Å‡∏≤‡∏™‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡πÑ‡∏î‡πâ"""
        score = 5  # base score
        
        # ‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡∏ó‡∏µ‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡πÑ‡∏î‡πâ‡πÑ‡∏î‡πâ‡∏î‡∏µ
        profitable_categories = ['technology', 'business', 'education', 'finance']
        if trend_data.get('category', '').lower() in profitable_categories:
            score += 2
        
        # keywords ‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ã‡∏∑‡πâ‡∏≠‡∏Ç‡∏≤‡∏¢
        commercial_keywords = ['buy', 'review', 'best', 'comparison', 'guide']
        keyword_matches = sum(1 for kw in trend_data.get('keywords', []) 
                             if any(commercial in kw.lower() for commercial in commercial_keywords))
        score += min(keyword_matches, 2)
        
        return min(score, 10)
    
    def generate_content_angles(self, trend_data):
        """‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏°‡∏∏‡∏°‡∏°‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤"""
        topic = trend_data['topic']
        keywords = trend_data.get('keywords', [])
        
        angles = [
            f"‡∏™‡∏≠‡∏ô‡∏ß‡∏¥‡∏ò‡∏µ‡πÉ‡∏ä‡πâ {topic} ‡πÅ‡∏ö‡∏ö‡∏á‡πà‡∏≤‡∏¢‡πÜ ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏°‡∏∑‡∏≠‡πÉ‡∏´‡∏°‡πà",
            f"‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö {topic} ‡∏Å‡∏±‡∏ö‡∏ó‡∏≤‡∏á‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏≠‡∏∑‡πà‡∏ô‡πÜ",
            f"‡πÄ‡∏Ñ‡∏•‡πá‡∏î‡∏•‡∏±‡∏ö‡πÅ‡∏•‡∏∞‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö {topic}"
        ]
        
        # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏°‡∏∏‡∏°‡∏°‡∏≠‡∏á‡∏ï‡∏≤‡∏° keywords
        if keywords:
            angles.append(f"‡∏ó‡∏≥‡πÑ‡∏° {keywords[0]} ‡∏ñ‡∏∂‡∏á‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡πÉ‡∏ô‡∏¢‡∏∏‡∏Ñ {topic}")
        
        return angles[:3]
    
    def generate_recommendations(self, viral_potential, content_saturation, audience_interest, monetization_opportunity):
        """‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥"""
        recommendations = []
        
        if viral_potential > 7:
            recommendations.append("‡∏°‡∏µ‡∏®‡∏±‡∏Å‡∏¢‡∏†‡∏≤‡∏û‡πÑ‡∏ß‡∏£‡∏±‡∏•‡∏™‡∏π‡∏á ‡∏Ñ‡∏ß‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÄ‡∏£‡πá‡∏ß‡πÜ")
        
        if content_saturation > 7:
            recommendations.append("‡∏ï‡∏•‡∏≤‡∏î‡∏≠‡∏¥‡πà‡∏°‡∏ï‡∏±‡∏ß ‡∏ï‡πâ‡∏≠‡∏á‡∏´‡∏≤‡∏°‡∏∏‡∏°‡∏°‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà‡πÜ")
        elif content_saturation < 4:
            recommendations.append("‡πÇ‡∏≠‡∏Å‡∏≤‡∏™‡∏î‡∏µ ‡∏°‡∏µ competition ‡∏ô‡πâ‡∏≠‡∏¢")
        
        if audience_interest > 7:
            recommendations.append("‡∏ú‡∏π‡πâ‡∏ä‡∏°‡∏™‡∏ô‡πÉ‡∏à‡∏™‡∏π‡∏á ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏ó‡∏≥ series")
        
        if monetization_opportunity > 7:
            recommendations.append("‡πÇ‡∏≠‡∏Å‡∏≤‡∏™‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡πÑ‡∏î‡πâ‡∏î‡∏µ ‡∏Ñ‡∏ß‡∏£ focus ‡∏ó‡∏µ‡πà quality")
        
        return " | ".join(recommendations) if recommendations else "‡πÅ‡∏ô‡∏ß‡πÇ‡∏ô‡πâ‡∏°‡∏õ‡∏Å‡∏ï‡∏¥ ‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏≤‡∏°‡πÅ‡∏ú‡∏ô"
    
    def estimate_views(self, trend_data):
        """‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏à‡∏≥‡∏ô‡∏ß‡∏ô views ‡∏ó‡∏µ‡πà‡∏Ñ‡∏≤‡∏î‡∏´‡∏ß‡∏±‡∏á"""
        base_views = trend_data['popularity_score'] * 1000
        
        if trend_data['growth_rate'] > 20:
            base_views *= 1.5
        
        return int(base_views)
    
    def assess_competition(self, trend_data):
        """‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÅ‡∏Ç‡πà‡∏á‡∏Ç‡∏±‡∏ô"""
        if trend_data['popularity_score'] > 80:
            return 'high'
        elif trend_data['popularity_score'] > 50:
            return 'medium'
        else:
            return 'low'
    
    def assess_production_difficulty(self, trend_data):
        """‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏Å‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ú‡∏•‡∏¥‡∏ï"""
        complex_topics = ['programming', 'finance', 'science']
        
        if any(topic in trend_data['topic'].lower() for topic in complex_topics):
            return 'high'
        elif 'tutorial' in trend_data['topic'].lower():
            return 'medium'
        else:
            return 'low'

class OpportunityGenerator:
    def __init__(self, db):
        self.db = db
        self.analyzer = AITrendAnalyzer()
    
    def generate_content_opportunities(self, min_score=6.0):
        """‡∏™‡∏£‡πâ‡∏≤‡∏á content opportunities ‡∏à‡∏≤‡∏Å trends"""
        try:
            from database.models_simple import TrendModel, ContentOpportunityModel
            
            trend_model = TrendModel(self.db)
            opportunity_model = ContentOpportunityModel(self.db)
            
            # ‡∏î‡∏∂‡∏á trends ‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î
            trends = trend_model.get_all()
            opportunities_created = 0
            
            print(f"üîç Analyzing {len(trends)} trends for content opportunities...")
            
            for trend in trends:
                # ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå trend
                analysis = self.analyzer.analyze_trend_potential(trend)
                
                # ‡∏™‡∏£‡πâ‡∏≤‡∏á opportunities ‡∏´‡∏≤‡∏Å‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏ú‡πà‡∏≤‡∏ô‡πÄ‡∏Å‡∏ì‡∏ë‡πå
                if analysis['scores']['overall_score'] >= min_score:
                    for angle in analysis['content_angles']:
                        opportunity_id = opportunity_model.create(
                            trend_id=trend['id'],
                            suggested_angle=angle,
                            estimated_views=analysis['estimated_metrics']['potential_views'],
                            competition_level=analysis['estimated_metrics']['competition_level'],
                            priority_score=analysis['scores']['overall_score'],
                            production_cost=self.estimate_production_cost(analysis),
                            estimated_roi=self.estimate_roi(analysis)
                        )
                        
                        if opportunity_id:
                            opportunities_created += 1
            
            print(f"‚úÖ Created {opportunities_created} content opportunities")
            return opportunities_created
            
        except Exception as e:
            print(f"‚ùå Error generating opportunities: {e}")
            return 0
    
    def estimate_production_cost(self, analysis):
        """‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ï‡πâ‡∏ô‡∏ó‡∏∏‡∏ô‡∏Å‡∏≤‡∏£‡∏ú‡∏•‡∏¥‡∏ï"""
        difficulty = analysis['estimated_metrics']['production_difficulty']
        
        cost_map = {
            'low': 50,     # ‡∏ö‡∏≤‡∏ó
            'medium': 150, # ‡∏ö‡∏≤‡∏ó
            'high': 300    # ‡∏ö‡∏≤‡∏ó
        }
        
        return cost_map.get(difficulty, 100)
    
    def estimate_roi(self, analysis):
        """‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô ROI"""
        potential_views = analysis['estimated_metrics']['potential_views']
        monetization_score = analysis['scores']['monetization_opportunity']
        
        # ‡∏™‡∏π‡∏ï‡∏£‡∏Ñ‡∏£‡πà‡∏≤‡∏ß‡πÜ: views * monetization_score * 0.001
        estimated_revenue = potential_views * monetization_score * 0.001
        estimated_cost = self.estimate_production_cost(analysis)
        
        if estimated_cost > 0:
            roi = (estimated_revenue - estimated_cost) / estimated_cost
            return max(roi, 0)  # ‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ‡∏ï‡∏¥‡∏î‡∏•‡∏ö
        
        return 0

def main():
    """‡∏ó‡∏î‡∏™‡∏≠‡∏ö AI Trend Analyzer"""
    print("ü§ñ Testing AI Trend Analyzer...")
    
    try:
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á database connection
        from database.models_simple import Database
        db = Database()
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á opportunity generator
        generator = OpportunityGenerator(db)
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á opportunities
        opportunities_count = generator.generate_content_opportunities(min_score=5.0)
        
        if opportunities_count > 0:
            # ‡∏î‡∏∂‡∏á opportunities ‡∏ó‡∏µ‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏°‡∏≤
            from database.models_simple import ContentOpportunityModel
            opportunity_model = ContentOpportunityModel(db)
            
            opportunities = opportunity_model.get_by_status('pending')
            
            print(f"\nüìã Top Content Opportunities:")
            for i, opp in enumerate(opportunities[:5], 1):
                print(f"{i}. {opp['suggested_angle']}")
                print(f"   Priority: {opp['priority_score']:.1f} | ROI: {opp['estimated_roi']:.2f}")
                print(f"   Views: {opp['estimated_views']} | Cost: ‡∏ø{opp['production_cost']}")
                print()
            
            return True
        else:
            print("‚ö†Ô∏è No opportunities created. Try running trend collection first.")
            return False
            
    except Exception as e:
        print(f"‚ùå AI Trend Analyzer test failed: {e}")
        return False

if __name__ == "__main__":
    main()