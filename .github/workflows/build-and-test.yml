name: Build and Test

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  workflow_dispatch:

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: ai-content-factory

jobs:
  # Job 1: Code Quality and Security Checks
  code-quality:
    name: Code Quality & Security
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0  # Shallow clones should be disabled for better analysis
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        cache: 'pip'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install flake8 black isort bandit safety
        if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
    
    - name: Code formatting check (Black)
      run: black --check --diff .
      continue-on-error: true
    
    - name: Import sorting check (isort)
      run: isort --check-only --diff .
      continue-on-error: true
    
    - name: Lint with flake8
      run: |
        # Stop the build if there are Python syntax errors or undefined names
        flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics
        # Exit-zero treats all errors as warnings
        flake8 . --count --exit-zero --max-complexity=10 --max-line-length=88 --statistics
      continue-on-error: true
    
    - name: Security check with bandit
      run: bandit -r . -x tests/ -f json -o bandit-report.json
      continue-on-error: true
    
    - name: Dependency security check
      run: safety check --json --output safety-report.json
      continue-on-error: true
    
    - name: Upload security reports
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: security-reports
        path: |
          bandit-report.json
          safety-report.json
        retention-days: 30

  # Job 2: Unit Tests
  unit-tests:
    name: Unit Tests
    runs-on: ubuntu-latest
    needs: code-quality
    
    strategy:
      matrix:
        python-version: ['3.9', '3.10', '3.11']
    
    services:
      postgres:
        image: postgres:13
        env:
          POSTGRES_PASSWORD: test_password
          POSTGRES_USER: test_user
          POSTGRES_DB: test_content_factory
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
      
      redis:
        image: redis:7
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}
        cache: 'pip'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install pytest pytest-cov pytest-asyncio
        if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
        if [ -f requirements-test.txt ]; then pip install -r requirements-test.txt; fi
    
    - name: Set up test environment
      run: |
        cp .env.example .env
        echo "DB_HOST=localhost" >> .env
        echo "DB_PORT=5432" >> .env
        echo "DB_NAME=test_content_factory" >> .env
        echo "DB_USER=test_user" >> .env
        echo "DB_PASSWORD=test_password" >> .env
        echo "REDIS_URL=redis://localhost:6379" >> .env
    
    - name: Run database migrations
      run: |
        python database/migrate.py
      env:
        DB_HOST: localhost
        DB_PORT: 5432
        DB_NAME: test_content_factory
        DB_USER: test_user
        DB_PASSWORD: test_password
    
    - name: Run unit tests
      run: |
        pytest tests/unit/ -v --cov=. --cov-report=xml --cov-report=html
      env:
        DB_HOST: localhost
        DB_PORT: 5432
        DB_NAME: test_content_factory
        DB_USER: test_user
        DB_PASSWORD: test_password
        REDIS_URL: redis://localhost:6379
    
    - name: Upload coverage reports
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
        flags: unittests
        name: codecov-umbrella
        fail_ci_if_error: false
    
    - name: Upload coverage artifact
      uses: actions/upload-artifact@v3
      with:
        name: coverage-report-${{ matrix.python-version }}
        path: htmlcov/
        retention-days: 30

  # Job 3: Integration Tests
  integration-tests:
    name: Integration Tests
    runs-on: ubuntu-latest
    needs: unit-tests
    
    services:
      postgres:
        image: postgres:13
        env:
          POSTGRES_PASSWORD: test_password
          POSTGRES_USER: test_user
          POSTGRES_DB: test_content_factory
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        cache: 'pip'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install pytest pytest-asyncio requests
        if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
    
    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3
    
    - name: Build test images
      run: |
        docker-compose -f docker-compose.yml -f docker-compose.test.yml build
    
    - name: Start services for integration tests
      run: |
        docker-compose -f docker-compose.yml -f docker-compose.test.yml up -d
        sleep 30  # Wait for services to be ready
    
    - name: Run integration tests
      run: |
        pytest tests/integration/ -v --tb=short
      env:
        TEST_ENVIRONMENT: integration
    
    - name: Collect service logs
      if: failure()
      run: |
        docker-compose logs > integration-test-logs.txt
    
    - name: Upload logs on failure
      if: failure()
      uses: actions/upload-artifact@v3
      with:
        name: integration-test-logs
        path: integration-test-logs.txt
        retention-days: 7
    
    - name: Clean up
      if: always()
      run: |
        docker-compose -f docker-compose.yml -f docker-compose.test.yml down -v

  # Job 4: Build Docker Images
  build-images:
    name: Build Docker Images
    runs-on: ubuntu-latest
    needs: [code-quality, unit-tests]
    
    outputs:
      image-digest: ${{ steps.build.outputs.digest }}
      image-tags: ${{ steps.meta.outputs.tags }}
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3
    
    - name: Log in to Container Registry
      if: github.event_name != 'pull_request'
      uses: docker/login-action@v3
      with:
        registry: ${{ env.REGISTRY }}
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}
    
    - name: Extract metadata
      id: meta
      uses: docker/metadata-action@v5
      with:
        images: ${{ env.REGISTRY }}/${{ github.repository }}/${{ env.IMAGE_NAME }}
        tags: |
          type=ref,event=branch
          type=ref,event=pr
          type=sha,prefix={{branch}}-
          type=raw,value=latest,enable={{is_default_branch}}
    
    # Build each service separately
    - name: Build and push trend-monitor
      uses: docker/build-push-action@v5
      with:
        context: ./trend-monitor
        file: ./trend-monitor/Dockerfile
        push: ${{ github.event_name != 'pull_request' }}
        tags: ${{ env.REGISTRY }}/${{ github.repository }}/trend-monitor:${{ github.sha }}
        labels: ${{ steps.meta.outputs.labels }}
        cache-from: type=gha
        cache-to: type=gha,mode=max
    
    - name: Build and push content-engine
      uses: docker/build-push-action@v5
      with:
        context: ./content-engine
        file: ./content-engine/Dockerfile
        push: ${{ github.event_name != 'pull_request' }}
        tags: ${{ env.REGISTRY }}/${{ github.repository }}/content-engine:${{ github.sha }}
        labels: ${{ steps.meta.outputs.labels }}
        cache-from: type=gha
        cache-to: type=gha,mode=max
    
    - name: Build and push platform-manager
      uses: docker/build-push-action@v5
      with:
        context: ./platform-manager
        file: ./platform-manager/Dockerfile
        push: ${{ github.event_name != 'pull_request' }}
        tags: ${{ env.REGISTRY }}/${{ github.repository }}/platform-manager:${{ github.sha }}
        labels: ${{ steps.meta.outputs.labels }}
        cache-from: type=gha
        cache-to: type=gha,mode=max
    
    - name: Build and push monitoring
      uses: docker/build-push-action@v5
      with:
        context: ./monitoring
        file: ./monitoring/Dockerfile
        push: ${{ github.event_name != 'pull_request' }}
        tags: ${{ env.REGISTRY }}/${{ github.repository }}/monitoring:${{ github.sha }}
        labels: ${{ steps.meta.outputs.labels }}
        cache-from: type=gha
        cache-to: type=gha,mode=max

  # Job 5: End-to-End Tests
  e2e-tests:
    name: End-to-End Tests
    runs-on: ubuntu-latest
    needs: [integration-tests, build-images]
    if: github.ref == 'refs/heads/main' || github.ref == 'refs/heads/develop'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '18'
        cache: 'npm'
        cache-dependency-path: web-dashboard/package-lock.json
    
    - name: Install E2E dependencies
      run: |
        cd web-dashboard
        npm ci
        npx playwright install
    
    - name: Set up test environment
      run: |
        cp .env.example .env.e2e
        echo "ENVIRONMENT=e2e" >> .env.e2e
    
    - name: Start application stack
      run: |
        docker-compose -f docker-compose.yml -f docker-compose.e2e.yml up -d
        sleep 60  # Wait for all services to be ready
    
    - name: Wait for services health check
      run: |
        timeout 300 bash -c 'until curl -f http://localhost:5000/health; do sleep 5; done'
        timeout 300 bash -c 'until curl -f http://localhost:3000; do sleep 5; done'
    
    - name: Run E2E tests
      run: |
        cd web-dashboard
        npm run test:e2e
      env:
        BASE_URL: http://localhost:3000
        API_URL: http://localhost:5000
    
    - name: Upload E2E test results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: e2e-test-results
        path: |
          web-dashboard/test-results/
          web-dashboard/playwright-report/
        retention-days: 30
    
    - name: Clean up E2E environment
      if: always()
      run: |
        docker-compose -f docker-compose.yml -f docker-compose.e2e.yml down -v

  # Job 6: Security Scan
  security-scan:
    name: Security Scan
    runs-on: ubuntu-latest
    needs: build-images
    if: github.event_name != 'pull_request'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Run Trivy vulnerability scanner
      uses: aquasecurity/trivy-action@master
      with:
        image-ref: '${{ env.REGISTRY }}/${{ github.repository }}/content-engine:${{ github.sha }}'
        format: 'sarif'
        output: 'trivy-results.sarif'
    
    - name: Upload Trivy scan results
      uses: github/codeql-action/upload-sarif@v2
      with:
        sarif_file: 'trivy-results.sarif'

  # Job 7: Build Summary
  build-summary:
    name: Build Summary
    runs-on: ubuntu-latest
    needs: [code-quality, unit-tests, integration-tests, build-images, e2e-tests]
    if: always()
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Generate build summary
      run: |
        echo "## ðŸš€ AI Content Factory Build Summary" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "**Build Information:**" >> $GITHUB_STEP_SUMMARY
        echo "- Branch: \`${{ github.ref_name }}\`" >> $GITHUB_STEP_SUMMARY
        echo "- Commit: \`${{ github.sha }}\`" >> $GITHUB_STEP_SUMMARY
        echo "- Triggered by: ${{ github.event_name }}" >> $GITHUB_STEP_SUMMARY
        echo "- Build time: $(date -u +%Y-%m-%dT%H:%M:%SZ)" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "**Job Results:**" >> $GITHUB_STEP_SUMMARY
        echo "- Code Quality: ${{ needs.code-quality.result }}" >> $GITHUB_STEP_SUMMARY
        echo "- Unit Tests: ${{ needs.unit-tests.result }}" >> $GITHUB_STEP_SUMMARY
        echo "- Integration Tests: ${{ needs.integration-tests.result }}" >> $GITHUB_STEP_SUMMARY
        echo "- Build Images: ${{ needs.build-images.result }}" >> $GITHUB_STEP_SUMMARY
        echo "- E2E Tests: ${{ needs.e2e-tests.result }}" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        if [[ "${{ needs.code-quality.result }}" == "success" && 
              "${{ needs.unit-tests.result }}" == "success" && 
              "${{ needs.integration-tests.result }}" == "success" && 
              "${{ needs.build-images.result }}" == "success" ]]; then
          echo "âœ… **Build Status: SUCCESS** - Ready for deployment!" >> $GITHUB_STEP_SUMMARY
        else
          echo "âŒ **Build Status: FAILED** - Please check the failed jobs above." >> $GITHUB_STEP_SUMMARY
        fi
    
    - name: Create deployment artifact
      if: github.ref == 'refs/heads/main' && needs.build-images.result == 'success'
      run: |
        mkdir -p deployment-artifacts
        echo "${{ github.sha }}" > deployment-artifacts/image-tag.txt
        echo "${{ github.ref_name }}" > deployment-artifacts/branch.txt
        echo "$(date -u +%Y-%m-%dT%H:%M:%SZ)" > deployment-artifacts/build-time.txt
    
    - name: Upload deployment artifacts
      if: github.ref == 'refs/heads/main' && needs.build-images.result == 'success'
      uses: actions/upload-artifact@v3
      with:
        name: deployment-artifacts
        path: deployment-artifacts/
        retention-days: 90